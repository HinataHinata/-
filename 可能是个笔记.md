#    还是写一个笔记吧
## ====我就是我 是颜色不一样的烟火 ====

# [2017-07-04 协程 python]

01. 英文名Coroutine
02. 协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比线程数量越多，协程的性能优势就越明显。
03. 第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。
04. 协程是用 generator 实现的 也就是 python 中的 yield 关键字
05. 实际上也是处理了调用与线程的关系。按照文档中的说法，是提出了新的 线程与调用的模型。函数调用可以认为是一种特殊的协程。协程本质上使用的是线程内部的中断技术。

# [2017-07-05 复习一下 python 教程 把没记住的知识点总结一哈]

01. print()函数也可以接受多个字符串，用逗号“,”隔开，就可以连成一串输出。遇到','的地方会输出空格
* 例如 print('1','2','3') 将输出 1 2 3

02. 通过 input() 函数获取输入 
* 例如 name = input() 或者带参数 name = input('please input your name:')

03. 字符串表示 r'' 前缀表示字符串不转义
* 例如 字符串中的内容是 \r\n 如果用转义则表示为 \\r\\n 或者表示为 r'\r\n'
* ‘’‘ 可以输入多行内容 并且用 ''' 结束
* '''前可以加上 r 前缀 表示不对多行内容进行转义 内容里可以有 \r\n 等内容

04. b 前缀表示 字符串的 bytes 数据
*例如 'ABC'.encode('ascii') = b'ABC' '中文'.encode('utf-8') = b'\xe4\xb8\xad\xe6\x96\x87'
*可以用 len() 函数 获取字符串或者 bytes 的长度

05. 格式化字符串
* %d 表示整数 %f 表示浮点数 %s 表示字符串 %x表示十六进制整数
* 整数和浮点数可以在前边补数字和0决定整数与小小数的位数
* '%2d-%02d' % (3,1)
* '%.2f' % 3.1415926
* '%010.2f'  % 3.1415926
* %s 会将任何数据类型转换为字符串
* 使用 %% 表示一个字符串 %

06. list 支持的一些方法

```py
len() # 获取元素个数
list[0] # 获取 index 个元素
list[-1] # 获取倒数第 index 个元素
list.append(element) # 向末尾添加元素
list.insert(1,element) # 插入元素
list.pop() # 删除并返回最后一个元素
list.pop(1) # 删除并返回第 index 个元素
list[1] = element # 修改元素
```
* list 中的元素可以使不同类型
* list 中可以包含一个 list


07. tuple 的一些问题
* tuple 是不可变的 list 必须在初始化的时候设定好元素内容
* 定义只有一个元素的tuple t = (1,) 因为写成 t = (1) 的时候，会被认为是 t = 1 被认为是一个变量
* 在 print 显示的时候也会显示为 t = (1,)

08. int(s) 把字符串转换为 int 类型

09. range(t) 表示生成从 0 开始到小于 t 的整数
* 可以使用 list() 函数转换为 list 例如 list(range(1,5)) = [1,2,3,4]
* range(t) 实际上是生成了 range(0,t) 对象 for in 可以作用于 range() 对象 遍历所有元素

10. dict 支持的相关操作
* x in dict 可以判断字典中是否存在某个元素，避免获取不存在的 key 报错
* 或者可以使用 dict 的获取方法 dict.get(key) dict.get(key,defaultValue) 来获取
* 可以使用 dict.pop(key) 从字典中删除元素
* dict 的 key 必须是不可变的对象

11. set 相关的操作 set 不包含重复的元素
* 使用 list 初始化 set  s = set([1,2,3])
* set.add(key) 向 set 中添加元素
* set.remove(key) 删除元素 set 删除元素的操作是 remove() 而不是 pop()

12. max() 函数可以接受任意多个参数 返回最大的元素,也可以接收 list 参数 返回 list 中最大的元素

13. 关于函数
* 函数可以返回多个值 也可以用多个变量接收函数的返回值。 例如 x,y = destination(originalX,originalY,move)
* 实际上 是通过 tuple 操作的。语法省略了这一过程。
* 函数可以有默认参数 即在函数头中设置默认值，例如 circle(x = 0,y = 0)
* 但是函数的默认参数需要指向不可变对象 因为 python 的实现中有一些细节问题，貌似不会干掉调用过程中的过程参数
* 举一个例子 def append_end(L = []):L.append('END') 这个方法在多次调用 append_end() 后会添加多个 END 因为过程参数没被干掉
* 所以需要修改为 
```py
def append_end(L=None):
    if L == None:
        L = []   
    L.append('END')
    return L
```

14. 函数的可变参数
* 可以通过参数名前加 * 的方式，传入可变参数 例如 def sum(*numbers): sum = 0 for x in numbers: sum = sum + x return sum
* 可以在 list 或者 tuple之前添加 * 的方式 将 list 和 tuple 转换为可变参数 例如 L = [1,2,3] sum(*L)

15. 可变参数
* 可变参数允许传入0个或任意个参数，这些可变参数在函数调用时自动组装为一个tuple。而关键字参数允许传入0个或任意个含参数名的参数，这些关键字参数在函数内部自动组装为一个dict.
* 不过这种方式传入的 dict 不会对字段 key 做限制
* 可以通过 命名关键字参数限制关键字 例如 def person(name,age,*,city,job): 或添加默认值 def person(name,age,*,city='BeiJing',job):

# [2017-07-06 继续复习 python]

01. 函数的尾递归优化 在函数的 return 语句调用自身 python 没有做尾递归优化
* 递归调用 HannoiTwer
```py
def HannoiTower(n,A,B,C):
    if n == 1:
        print(A,'->',C)
    else:
        move(n-1,A,C,B)
        print(A,'->',C)
    move(n-1,B,A,C)
move(3,'A','B','C')
```
02. python 提供了下标的切片操作 list tuple string 都可以使用切片
* 切片的大致规则是 list[from:to:step] 同时，参数支持负数 -1 表示倒数第一个
03. 可以用于 for-in 的对象称为 Iterable 可以用 isinstance(object,Iterable) 判断是否可以用于 for-in 语句
04. 可以用 enumerate() 方法获取 list 的索引 例如 for i,value in enumerate([1,2,3])
05. 列表生成式
```py
[x * x for x in range(10)] # 一般形式
[x * x for x in range(10) if x %2 == 1] # 添加条件形式
[m + n for m in 'ABC' for n in 'abc']
import os
[d for d in os.listdir('.')] # 列出当前目录
d = {'1':'A','2':'B'}
[k + '=' + v for k,v in d.items()] dict.items() # 获取字典元素的 key-value 对
```

06. 生成器 generator python 中一种一边循环一遍计算的机制    
* g = (x * x for x in range(10)) 即可创建一个列表生成器
* next() 方法可以获取 generator 的下一个元素值 超出范围后 抛出 StopIteration 错误
* 可以用 for-in 语句依次获取 generator 中的对象 遍历结束之后循环终止。
* 可以用 yield 关键字创建生成器 生成器在 yield 关键字处返回，下次执行的时候从 yield 关键字继续执行。

07. 可以用于 for-in 操作的对象称为可迭代对象。 如 list tuple dict set str 和 generator
* 可以用 isinstance(object,Iterable) 判断是不是一个可迭代对象
* 迭代器 不仅可以用于 for-in 操作，还可以使用 next(object) 获取下一个对象。
* 可以用 iter() 将list dict str 转换为迭代器。转换之后得到的结果是 generator 的子类
* 可以看到：
```py
    iter(list) = list_iterator isinstance(iter(list),generator) = True
    iter()iter = str_iterator isinstance(iter('abc'),generator) = True
```

08. 高阶函数 函数可以用函数作为参数 称为高阶函数 例如：
```py
def add(x,y,f):
    return f(x)+f(y)
```

09. map/reduce
* 在 python 中使用 reduce 需要 from functools import reduce
* map 的一般形式 map(f,L) f 函数依次作用于 L 中的元素 然后生成新的 generator 可以用 list() 函数转换为一个 list
* reduce 的一般形式 reduce(f,L) f 函数接受两个参数 返回一个结果 依次作用于 L 中的所有元素 类似于 小鱼吃豆豆

10. 有一个操作需要习惯一下 - 在函数内部定义函数。
* 这种写法个人感觉不适很好，但是有的时候还是比较有用的。
```py
def prod(L):
    def mul(x,y):
        return x*y
    reduce(mul,L)
pord([1,2,3,4,5])
```

11. filter() 方法 接收一个函数 f 和一个list f 依次作用于 list 中的每个元素，然后生成一个 generator 
* 通过写一个例子可以看出 filter 中的 f 函数是在获取 generator 中的元素的时候，采真正执行的
```py
def zcfilter(num):
    print('calling zcfilter...')
    return num % 2 == 0
L = filter(zcfilter,[1,2,3,4,5,6,7,8,9])
list(L)
```

12. sorted 函数可以用于排序 基本使用方法 sorter(L,key= abs,reverse=True) 其中 key 参数将作用于 L 中的元素，然后参与排序 并且 不会改变 L 的值
13. 字符串方法的调用一般可以使用两种形式 'ABC'.lower() 'ABC'.capitalize() 和 str.lower('ABC') str.capitalize('ABC')

# [2017-07-07 继续复习 python]

01. 高阶函数可以返回函数。 返回的函数在返回结果执行的时候真正的执行。
```py
def lazy_sum(*args):
    def sum():
        ax = 0
        for n in ax:
            ax = ax + n
        return ax
    return sum

f = lazy_sum(1,2,3,4,5) # 此时，sum() 函数并没有真正的执行
result = f() # 这个时候，才真正的执行 sum()
print(result)

# 调用 lazy_sum() 时，每次都会返回一个新的函数，即使参数时一样的
f1 = lazy_sum(1,2,3)
f2 = lazy_sum(1,2,3)
f1 == f2 (False)
```
02. 闭包的概念 把相关参数和变量都保存在返回的函数中
* 返回函数不可以引用任何循环变量，除非是可以这样做的。因为返回的函数是在真正调用的时候才执行的，所以依赖循环变量的函数会发生参数错误。

03. 匿名函数 就是传说中的 lambda 表达式
* 匿名函数 只能有一个表达式，不用写 return 返回值就是表达式的结果。
```py
# lambda 表达式表示为函数形式
lambda x: x * x
def f(x):
    return x * x
```
* 匿名函数可以赋值给变量，也可以作为函数的返回值返回。
* python 对匿名函数的支持有限。

04. 装饰器 装饰器的原理是 修改原函数指向的对象，指向一个返回原函数的函数，并在这个函数中做一些额外的操作。
* 函数可以赋值给变量，通过 () 操作符执行。 函数有一个 __name__的属性，可以拿到函数的名字。
```py
def doSomething():
    print('dosomething')
f = doSomethign
f()
# 获取函数名称
doSomething.__name__
f.__name
```
* 定义一个打印调用函数名字的 log 函数
```py
def log(func):
    def wrapper(*args,**kw):
        print('call %s():' % func.__name__)
        return func(*args,**kw)
    return wrapper

@log 
def bark():
    print('barking...')

bark()
```
* 把 @log 放到函数 bark 的定义处 相当于执行了语句 bark = log(bark) 即 改变了函数的定义，用包装过后的函数替代之前的函数。
* 下边这个例子可以看的更清楚
```py
def lightOn():
    print('turn light on...')

f = log(lightOn)
f # <function log.<locals>.wrapper>
f() # call lightOn() turn light on
lightOn.__name__ # wrapper
```
* 实际上就是通过返回函数，玩了一个修改函数指针的小把戏
* 如果需要定义打印的文字的话，为了传入参数，需要多定义一层函数 即最外层函数返回 装饰器
```py
def log(text):
    def decorator(func):
        def wrapper(*args,**kw):
            print('%s %s():' % (text,func.__name__))
        return wrapper
    return decorator
```
* 三层嵌套的调用套路是 log('description')(func)() 执行
* 由于使用 wrapper 之后，func.__name__ 是 wrapper 依赖 __name__ 的代码就会出问题，所以 python functools.wraps 专门处理了这个问题 import functools 之后 在 wrapper() 上加上 @functools.wraps(func) 即可修正函数名
```py
import functools
def log(func):
    @functools.wraps(func)
    def wrapper(*args,**kw):
        print('calling %s()' % func.__name__)
        return func(*args,**kw)
    return wrapper

@log
def bark():
    print('dog bark')

bark() # balling bark() dog bark
bark.__name__ # 'bark'
```

05. 偏函数 python 支持从一个函数添加默认参数直接创建另外一个函数 需要 import functools
```py
import functools
int2 = functools.partial(int,base=2)
int2('1000000') # 64
int2('1010101') # 85
#类似于编写了一个函数
def int2(x):
    return int(x,base=2)
```
* functools.partial(func,argument) 会将参数添加到 func 的参数列表中
```py
#import functools
int2 = functools.partial(int,base=2) # 相当于 kw = {'base':2} int('10010',**kw)
max2 = functools.partial(max,10) # 会将 10 添加到参数列表中
max2(1,2,7) # 相当于 max(10,1,2,7)
```
06. 模块 为了维护代码，把相关脸的代码放到一个组里，称为模块。python 中一个 .py 文件就是一个模块
* 可以把多个 python 文件放入一个包中 例如 web.abc web.xyz 每一个包目录下都会有一个 __init__.py 文件，这个文件可以是空文件也可以有代码。如果没有这个文件， python 就会把目录当成一个普通目录，而不是当成一个包。
* 包可以有上下级的层级结构 但是每一层都要有一个 __init__.py 文件

07. 使用模块 import + 包名 后可以使用包中的组件。
* import sys 可以使用 sys 模块。 sys.argv 可以获取参数

08. 作用域
* 正常函数和变量名是公开的 (public) 
* 类似 __xxx__ 这样的变量是特殊变量，可以被直接引用，但是有特殊用途，比如 __author__访问作者名,__name__访问文件名,__doc__ 访问文档注释。 自己一般不要定义这种变量名。
* 类似 _xxx 和 __xxx 这样的函数或变量就是非公开的，(private)，不应该直接被引用。

09. 安装第三方模块
* 通过包管理工具 pip 完成。
* 安装第三方库 pip3 install xxx 使用第三方库 import xxx 或者 from xxx import yyy
* import sys sys.path 可以打印 python 的环境变量

10. 面向对象编程
* python 定义累对象的方式比较随意，随手一写就是一个属性。
```py
class Student(object):
    def __init__(self,name,score):
        self.name = name
        self.score = score
    def print_score(self):
        print('%s %s' % (self.name,self.score)
```
11. 类和实例
* 属性的赋值也很随意，就算没有这个属性，也可以给这个属性赋值，会添加一个叫这个名字的属性。 别人知不知道就看他自己本事了。
* 实例变量必须包含的属性需要在 __init__(self) 方法中定义。

12. 访问限制
* 属性名前加上 __ 可以不被外部访问。例如在 　__init__ 中写到 self.__name = name 就不能直接访问 __name 了
* 如果需要访问权限 可以使用 set／get 方法提供访问方式。
* 实际上 __name 属性是被改了名字，可以通过 self._classname__name访问。但是最好不要这个样子。

13. 获取对象信息
* 可以通过 type() 函数获取一个对象的类型信息。例如 type('123') type(123) type(abs)
* types 模块包含了关于类型的信息 import 之后可以使用 例如 types.FunctionType types.BuildinFunctionType types.lambdaType
* 可以使用 isinstance 判断是不是某个类型及其子类。 还可判断是不是某些类型中的一种
```py
 isinstance([1,2,3],(list,tuple))
```
* 可以使用 dir() 方法获取一个对象的所有属性和方法。
```py
dir('abc')
```
* len(object) 实际上是调用了 object.__len__() 如果想要自己的类型支持 len(yourObject) 需要在自己的类中 实现 __len__()方法。
* hasattr(obj,'x') setattr(obj,'x') getattr(obj,'x') getattr(obj,'x',defaultValue) 功能分别如方法名所说。
* read() 方法是流式对象的方法，可以是文件流，可以是网络流，总之是流，有点像接口的概念。

14. 实例属性和类属性 
* 当实例对象属性不存在时，将返回类的同名属性的值。类属性可以用类访问也可以用实例访问。 尽量不要使用相同名称的类属性和实例属性。
* 使用 del s.name 删除实例对象的属性。 就算是 __init__ 文件中定义的属性也可以删除。真是醉醉的。

15. 面向对象高级编程
* 给实例变量绑定方法。 需要 from types import MethodType
```
class Student(object):
    pass

def set_age(self,age):
    self.age = age

from types import MethodType
s.set_age = MethodType(set_age,s)
```
* 给实例绑定方法不会影响其他实例对象。 如果要对所有实例起作用，需要给类添加方法。
```py
class Student(object):
    pass
def set_score(self,score):
    self.score = score
Student.set_score = set_score
```
* 如果不想对象动态添加乱七八糟的属性，可以使用 __slots__ 关键字加以限制
```py
class Student(object):
    __slot__ = ('name','score')
```
* 使用 __slot__ 关键字只对当前类起作用 不会影响子类。如果在子类中也添加了 __slots__ 关键字 那么属性就是子类 __slots__ 加上父类 __slots__

# [2017-07-08 继续复习 python]

01. 属性 python 中属性用装饰器实现。如果不定义 setter 就是只读属性。
```py
# 感觉 python 定义属性的方式好蠢。
class Student(object):
    @property
    def birth(self):
        return self._birth

    @birth.setter
    def birth(self,value):
        self._birth = value

    @property
    def age(self)
        return 2017 - self._birth
```

02. 多重继承 多重继承在继承的父类中用 , 隔开就好。表示一个概念上的多重继承。
```py
class Dog(Animal,Runnable):
    pass
```

03. 定制类 类似于 __xxx__ 这样的变量在 python 中是有特殊用途的。
* __str__ 变量可以定制对象在打印的时候的内容
```py
class Student(object):
    def __init__(self,name):
        self.name = name

    def __str__(self):
        return 'Student object (name:%s)' % self.name

print(Student('XiaoMing'))
```
* __iter__ 如果想要被用于 for-in 操作，需要实现一个 __iter__() 方法，该方法返回一个迭代对象，for 循环会调用该对象的 __next__() 方法获取下一个值。
```py
class Fib(object):
    def __init__(self):
        self.a = 1
        self.b = 1
    def __iter__(self):
        return self
    def __next__(self):
        if self.b < 10000:
            self.a,self.b = self.b,self.a+b
            return self.a
        else:
            raise StopIteration()

for n in Fib():
    print(n)
```
* __getitem__ 使对象支持按索引取元素。
```py
class Fib(object):
    def __getitem__(self,n)
        a,b = 0,1
        for x in range(n):
            a,b = b,a+b
        return a
Fib(0)
Fib(1)
Fib(2)
```
* 但是 list 支持切片操作，如果要支持切片操作，__getitem__ 还需要做一些额外的工作。
```py
class Fib(object):
    def __getitem__(self,n):
        if isinstance(n,int):
            a,b = 0,1
            for x in range(n):
                a,b = b,a+b
            return a
        if isinstance(n,slice): # 如果是切片的话
            start = n.start
            stop = n.stop
            if start is None:
                start = 0
            a,b = 1,1
            L = []
            for x in range(stop):
                if x >= start:
                    L.append(a)
                a,b = b,a+b
            return L
```
* __getattr__ 如果调用未定义的属性的话，会通过 __getattr__ 尝试获取结果。
```py
class Student(object):
    def __init__(self):
        self.name = 'XiaoMing'
    def __getattr__(self,attr):
        if attr == 'score':
            return 99
        if attr == 'age':
            return lambda:25 # 也可以返回函数 student.age() 调用
```
* 需要注意，__getattr__ 默认返回None (什么鬼，这不是搞笑吗。。) 如果要 class 只响应几个特定的属性，需要跑出 AttributeError 错误。
```py
class Student(object):
    def __getattr__(self,attr):
        if attr == 'age':
            return lambda:25
        raise AttributeError('\'Student\' object has no attribute \'%s\'' % attr)
```
* __call__ 定义之后可以在对象上 执行 ()
```py
class Student(object):
    def __init__(self,name='XiaoMing'):
        self.name = name
    def __call__(self):
        print('My name is %s' % self.name)
stu = Student('XiaoFang')
stu()
# 可以使用 callable() 判断是否支持 () 操作
callable(stu) # True
callable('abc') # False
```

04. 使用枚举量
```py
from enum import Enum
Month = Enum('Month',('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'))

for name,member in Month.__members__.items():
    print(name,'=>',member.value)
* 如果要定义变量值，需要定义 Enum 的子类
```py
from enum import Enum
@unique
class Weekday(Enum):
    Sun = 0
    Mon = 1
    Tue = 2
    Wed = 3
    Thu = 4
    Fri = 5
    Sat = 6
# 支持多种访问方式
Weekday.Mon
Weekday(1)
```

05 使用元类 metaclass 用于创建类
* type 可以获取对象的类型，也可以用于创建类型。
```py
class Hello(object):
    def hello(self):
        print('Hello World')

h = Hello()
type(Hello) # <class 'type'>
type(h) # <class '__main__.Hello'>
type(h.hello) # <class 'method'>

# 创建类对象
def fn(self):
    print('Hello World')

Hello = type('Hello',(object,),dict(hello=fn)) # 创建 Hello class
h = Hello()
h.hello()
print(type(Hello)) # <class 'type'>
print(type(h)) # <class '__main__.Hello'>
```
* metaclass 用于限制创建类的行为。默认习惯className+Metaclass 命名 例如 ListMetaclass
```py
# metaclass 是类的模版 从type派生
class ListMetaclass(type):
    def __new__(cls,name,bases,attrs):
        attrs['add'] = lambda self,value:self.append(value)
        return type.__new__(cls,name,bases,attrs)
class MyList(list,metaclass=ListMetaclass):
    pass
```
* 当定义了 metaclass 参数，python 的解释器在创建 MyList 时要通过 ListMetaclass.__new__() 来创建
* __new__() 方法接收到的参数依次是 当前准备创建的类的对象，类的名字 类继承的父类的集合 类的方法集合。
```py
L = MyList()
L.add(1)
print(L)
```
* 这种操作一般用在需要动态添加方法的情况下。例如做一个 ORM。所有的方法需要动态添加。

# [2017-07-09 继续复习 python]

01. python 中使用 try except finally 进行异常捕获。
```py
try:
    print('try...')
    r = 10/0
    print('result:',r)
except ZeroDivisionError as e:
    print('except:',e)
finally:
    print('finally...')
print('END')
```
02. python 的错误也是类，错误类型的基类是 BaseException 异常会捕获子类型错误。

03. logging 模块可以打印错误信息。 在异常捕获部分 调用 logging.exception(e) 需要 import logging

04. raise 语句用于抛出异常，可以自定义错误类型然后抛出异常。
```py
class FooError(ValueError):
    pass

def foo(s):
    n = int(s)
    if n == 0:
        raise FooError('invalid value:%s' % s)
    return 10/n

foo('0')
```

05. raise 语句如果不带参数，将把原有异常继续向上层抛出。
```py
def bar():
    try:
        foo('0')
    except ValueError as e:
        # 记录错误 并继续抛出。
        print('ValueError')
        raise

bar()
```

# [2017-07-10 继续复习 python]

01. 在家里的 Windows 台式机安装了 python 和 tensorflow
* 喝了剩下宝贝的冰粥，还可以。

# [2017-07-11 继续复习 python]

01. 今天准备一下考试。

# [2017-07-12 继续复习 python]

01. 使用 Metaclass 示例 ORM
```py
class Field(object):
    def __init__(self,name,column_type):
        self.name = name
        self.column_type = column_type

    def __str__(self):
        return  '<%s:%s>' % (self.__class__.__name__,self.name)

# 子类化 Field
class StringField(Field):
    def __init__(self,name):
        super(StringField,self).__init__(name,'varchar(100)')

class IntegerField(Field):
    def __init__(self,name):
        super(IntegerField,self).__init__(name,'bigint')

# Model MetaClass
class ModelMetaclass(type):
    def __new__(cls,name,bases,attrs):
        print('ModelMetaclass name:%s' % name)
        if name == 'Model':
            return type.__new__(cls,name,bases,attrs)
        print('Found Model: %s' % name)
        mappings = dict()
        for k,v in attrs.items():
            if isinstance(v,Field):
                print('Found mapping:%s ==> %s' % (k,v))
                mappings[k] = v
        for k in mappings.keys():
            attrs.pop(k)
        attrs['__mappings__'] = mappings; # 保存属性列表映射关系
        attrs['__table__'] = name # 假设表名和类名一致
        return  type.__new__(cls,name,bases,attrs)

class Model(dict,metaclass= ModelMetaclass):
# Model 类接收一个字典参数。
    def __init__(self,**kw):
        super(Model,self).__init__(**kw)
    def __getattr__(self, key):
        try:
            return self[key]
        except KeyError:
            raise AttributeError(r"'Model' object has no attribute '%s'" % key)

    def __setattr__(self, key, value):
        self[key] = value

    def save(self):
        fields = []
        params = []
        args = []

        for k,v in self.__mappings__.items():
            fields.append(v.name)
            params.append('?')
            args.append(getattr(self,k,None))
        sql = 'insert into %s (%s) values (%s)' % (self.__table__,','.join(fields),','.join(params))
        print('SQL:%s' % sql)
        print('ARGS:%s' % str(args))

class User(Model):
# 定义类的属性到数据库字段到映射
    id = IntegerField('id')
    name = StringField('username')
    email = StringField('email')
    password = StringField('password')

u = User(id = 12345,name = 'XiaoMing',email = 'xiaoming@163.com',password = '123456')
# 保存到数据库
u.save()
```

02. 断言 断言可以替代 print 在调试的时候输出日志
```py
def foo(s):
    n = int(s)
    assert n != 0,'n is zero!' # 当 assert 语句为 false 时，会抛出 AssertionError 并输出日志。
    return 10/n
def main():
    foo('0')
```
* 在启动 python 解释器的时候，可以通过 -o 参数关闭 assert。关闭之后，可以把 assert 当作 pass。

03. logging 也可以记录日志 并且可以输出到文件。
```py
import logging
logging.basicConfig(level=logging.INFO)
s = '0'
n = int(s)
logging.info('n=%d' % n)
print(10/n)
```
* logging 可以指定记录信息的级别。从上倒下依次为 debug/info/warning/error 当指定 level 为 info 时，debug 信息就不会输出了。
```py
logging.basicConfig(filename='logger.log',level = logging.INFO)
```

04. pdb 使用命令行启动 pdb 模式调试 python (太费劲了 忽略) & 使用 IDE 调试 python

05. 单元测试 需要引入 python 自带的单元测试模块 import unittest
* 以 test 开头的方法就是测试方法，不以 test 开头的方法测试的时候不执行
* unittest.TestCase 提供很多内置的条件判断 如self.assertEqual() self.assertTrue()
* with 语句可以测试是否抛出制定类型的异常。
* 运行测试单元 
    * 一种是在测试文件末尾加上 if __name__ == '__main__': unittest.main()
    * 另外一种是在命令行中通过参数 -m unittest 直接运行单元测试 例如 python3 -m unittest mydict_test
* setUp 和 tearDown 这两个方法分别在每一个测试方法调用之前和之后执行。
* 测试代码不可以过于复杂 过于复杂的测试代码可能本身就有 bug
* 示例测试一个 dict 类
```py
# mydict.py
class myDict(dict):
    def __init__(self,**kw):
        super().__init(**kw)
    def __getattr__(self,key):
        try:
            return self[key]
        except KeyError:
            raise AttributeError(r"'Dict' object has no attribute '%s'" % key)
    def __setattr__(self,key,value):
        self[key] = value
```
```py
#myDict_test.py
import unittest
from mydict import myDict
class TestMyDict(unittest.TestCase):
    def test_init(self):
        d = myDict(a = 1,b = 'test')
        self.assertEqual(d.a,1)
        self.assertEqual(d.b,'test')
        self.assertTrue(isinstance(d,dict))

    def test_key(self):
        d = myDict()
        d['key'] = 'value'
        self.assertEqual(d.key,'value')
    
    def test_attr(self):
        d = myDict()
        d.key = 'value'
        self.assertTrue('key' in d)
        self.assertEqual(d['key'],'value')

    def test_keyerror(self):
        d = myDict()
        with self.assertRaises(KeyError):
            value = d['empty']
    
    def test_attrerror(self):
        d = myDict()
        with self.assertRaises(AttributeError):
            value = d.empty


if __name__ == '__main__':
    unittest.main()
```

06. 文档测试 文档中的测试示例程序。可以被某些工具提取。用到的时候需要仔细看一下。一般编写对外使用的库的时候才会用到。

07. IO 操作 根据实现方式的不同可以分为 同步IO 和 异步IO

08. 文件读写操作
* 读文件
```py
# open - read - close
f = open('/Users/filepath','r')
f.read()
d.close()

# IO 操作比较容易发生错误 需要 try... finally
try:
    f = open('/Users/filepath','r')
    print(f.read())
finally:
    if f:
        f.close()
# with 语句 自动 close
with open('/Users/filepath','r') as f:
    print(f.read())
```
* read() 方法会一次性返回所有内容 如果内容过大 内存受不了。可以反复调用 read(size) - 读取制定大小的内容 readline() - 读入一行 readlines() 读取多行。
```py
for line in f.readlines():
    print(line.strip()) # 把末尾的 '\n' 删掉
```
* 读取二进制文件 f = open('/Users/filepath','rb')
* 指定文件编码格式 f = open('/Users/filepath','r',encoding='gbk')
* 指定字符错误处理方式 f = open('/Users/filepath','r',encoding='gbk',errors= 'ignore')
```py
# 都是通过字符串传递参数的 这样真的好吗？
```
* 写文件 和读文件操作基本一致
```py
f = open('/Users/filepath','w')
f.write('content to write')
f.close()
# with 语句
with open('/Users/filepath','w') as f:
    f.write('content to write')
```

09. StringIO 和 BytesIO 在内存中读写 String 和 Bytes
* StringIO 读写字符串
```py
from io import StringIO
f = StirngIO()
f.write('Hello') # 5
f.write(' ') # 1
f.write('World') # 5
print(f.getvalue()) # 'Hello World'

# 也可以用字符串初始化 StringIO
f = StringIO('Hello!\nHi!\nGoodbye!')
while True:
    s = f.readline()
    if s == '':
        break
    print(s.strip())
```
* BytesIO 读写 Bytes
```py
from io import BytesIO
f = BytesIO()
f.write('中文'.encode('utf-8'))
print(f.getvalue())
```

# [2017-07-13 继续复习 python]

01. 操作文件和目录 python 内置的 os 模块提供了调用操作系统提供的接口函数
* 部分方法说明 
```py
import os
os.name # 操作系统类型 posix
os.uname # 详细的操作系统信息
os.environ # 获取环境变量
```
* 操作文件和目录
```py
# 查看当前目录的绝对路径
os.path.abspath('.')
# 使用 path.join() 查看生成的心目录格式 不同操作系统的实现不一样
os.path.join('/Users/username','testdir') # '/Users/username/testdir'
# 使用 path.split() 拆分目录 返回 ('/Users/username','testdir')
os.path.split('/Users/username/testdir') 
# 创建一个目录
os.mkdir('/Users/username/testdir')
# 删掉一个目录
os.rmdir('/Users/username/testdir')

# 文件操作 文件重命名
os.rename('test.txt','test.py')
# 删掉文件
os.remove('test.py')

# python 中的 os 模块不支持复制文件 原因是操作系统不支持复制文件 复制文件可以使用 shutil 模块
# 列出当前目录下的所有目录
[x for x in os.listdir('.') if os.path.isdir(x)]
# 列出所有 .py 文件
[x for x in os.listdir('.') if os.path.isfile(x) and os.path.splitext(x)[1] == '.py']
```

02. 序列化 python 通过 pickling 模块序列化和反序列化
```py
# 序列化
import pickle
d = dict(name='Bob',age=20,score=88)
pickle.dumps(d)

f = open('dump.txt','wb')
pickle.dump(d,f)
f.close()
# 或者
with open('dump.txt','wb') as f:
    pickle.dump(d,f)

# 反序列化
with open('dump.txt','rb') as f:
    d = pickle.load(f)
    print(d)

```
* pickle 的序列化和反序列化在不同版本的 python 中是不兼容的 因此不能用来存储重要内容。

03. JSON 如果内容需要在不同编程语言／磁盘／网络传输的话，JSON是非常方便的。 JSON是一种自描述的字符串。
* python 内置了 JSON 模块
```py
# 将一个对象转换为 JSON 对象
import json
d = dict(name='XiaoMing',age=20,score=90)
json.dumps(d) # '{"name": "XiaoMing", "age": 20, "score": 90}'

* JSON 保存实例对象 需要先转换为 dict 在序列化 反序列化也是先得到一个dict再组装对象。
```py
import json
class Student(object):
    def __init__(self,name,age,score):
        self.name = name
        self.age = age
        self.score = score
def student2dict(std):
    return{'name':std.name,'age':std.age,'score':std.score}
aStudent = Student('XiaoMing',20,90)
json.dumps(aStudent,default = student2dict)
# 或者
json.dumps(aStudent,default = lambda obj:obj.__dict__)
# 反序列化
def dict2student(d):
    return Studnet(d['name'],d['age'],d['score'])
json_str = '{'name': 'XiaoMing', 'age': 20, 'score': 90}'
json.loads(json_str,object_hook = dict2student) # 注意一下这两个参数
```

04. 多进程 需要引入 multiprocessing 模块 python 中把进程抽象为 Process 对象
```py
from multiprocessing import Process
import os
# 子进程要执行的代码
def run_proc(name):
    print('Run child process %s (%s)' % (name,os.getpid()))

if __name__ == '__main__':
    print('Parnent process %s ' % os.getpid())
    p = Process(target=run_proc,args=('test',))
    print('Child process will start.')
    p.start() # 开始执行线程的工作
    p.join() # 等待子进程结束后再继续往下运行
    print('Child process end.')

# result
# Parnent process 1491 
# Child process will start.
# Run child process test (1492)
# Child process end.
```
* 如果要启动大量的子进程，可以用进程池的方式批量创建子进程
```py
from multiprocessing import Pool
import os,time,random

def long_time_task(name):
    print('Run task %s (%s)...' % (name,os.getpid()))
    start = time.time()
    time.sleep(random.random() * 3)
    end = time.time()
    print('Task %s runs %0.2f seconds' % (name,(end - start)))

if __name__ == '__main__':
    print('Parent process %s.' % os.getpid())
    p = Pool(4)
    for i in range(5):
        p.apply_async(long_time_task,args = (i,))
    print('Waiting for all subprocesses done...')
    p.close()
    p.join()  # Pool 对象调用 jion() 方法会等待所哟子进程执行完毕 在调用 join() 之前必须调用 close() 
    print('All subprocesses done.')
```

05. 子进程 创建子进程之后，控制子进程的输入和输出
```py
import subprocess
print('$ nslookup www.python.org')
r = subprocess.call(['nslookup','www.python.org'])
print('Exit code:',r)
```
* 如果子进程还需要输入，可以通过 communicate() 方法输入
```py
import subprocess
print('$ nslookup')
p = subprocess.Popen(['nslookup'],stdin=subprocess.PIPE,stdout = subprocess.PIPE,stderr = subprocess.PIPE)
output,err = p.communicate(b'set q=mx\npython.org\nexit\n')
print(output.decode('utf-8'))
print('Exit code:',p.returncode)

# 相当于在命令行输入 
# nslookup 
# set q=mx
# python.org
# exit
```

06. 进程间通信 python 的 multiproces 模块提供了通过 Queue 和 Pipes 的方式来交换数据
```py
from multiprocessing import Process,Queue
import os,time,random

# 写数据进程执行的代码
def write(q):
    print('Process to write:%s' % os.getpid())
    for value in ['A','B','C']:
        print('Put %s to queue...' % value)
        q.put(value)
        time.sleep(random.random())

# 读数据进程执行的代码
def read(q):
    print('Process to read:%s' % os.getpid())
    while True:
        value = q.get(True)
        print('Get %s from queue.' % value)

if __name__ == '__main__':
    # 父进程创建 Queue 并传给各个子进程
    q = Queue()
    pw = Process(target=write,args=(q,))
    pr = Process(target=read,args=(q,))
    # 启动子进程 写入 - 读取
    pw.start()
    pr.start()
    pw.join()
    # pr 是死循环 无法等待其结束 只能强行终止
    pr.terminate()

/* result
Process to write:2872
Put A to queue...
Process to read:2873
Get A from queue.
Put B to queue...
Get B from queue.
Put C to queue...
Get C from queue.
*/
```

07. 多线程 python 中提供两个模块，_thread 和 threading。前者是低级模块，后者对前者进行了封装。
* 使用示例
```py
import time,threading

# 新线程执行的代码
def loop():
    print('thread %s is running...' % threading.current_thread().name)
    n = 0
    while n < 5:
        n = n+1
        print('thread %s >>> %s' % (threading.current_thread().name,n))
        time.sleep(1)
    print('thread %s ended' % threading.current_thread().name)

print('thread %s is running...' % threading.current_thread().name)
t = threading.Thread(target=loop,name='LoopThread')
t.start()
t.join()
print('thread %S ended' % threading.current_thread().name)
```py
# 测试多线程修改同一个变量时发生的错误
import time,threading
balance = 0
def change_it(n):
    global balance
    balance = balance + n
    balance = balance -n

def run_thread(n):
    for i in range(100000):
        change_it(n)

def test_multithread():
    t1 = threading.Thread(target=run_thread,args=(5,))
    t2 = threading.Thread(target=run_thread,args=(8,))
    t1.start()
    t2.start()
    t1.join()
    t2.join()
    print(balance)
    time.sleep(0.1)


for i in range(100):
    balance = 0
    test_multithread()
# 可以看到结果不全是 0
```
* 为了避免多线程修改同一个变量发生的错误 需要使用 Lock
```py
lock = threading.Lock()
def run_thread(n):
    for i in range(100000):
        # 先获取锁
        lock.acquire()
        try:
            change_it(n)
        finally:
        #释放锁
            lock.release()
```
* 由于 python 解释器的实现的原因 python 不能占满多核 CPU python 解释器 有一个GIL(Global Interpreter Lock)锁。

08. ThreadLocal 每个线程都有自己的局部变量 为了解决函数调用中多次传参的问题 python 内置了 ThreadLocal
```py
import threading
# 创建全局 ThreadLocal 对象
local_school = threading.local()

def process_student():
    # 获取当前线程关联的 student
    stu = local_school.student
    print('Hello,%s (in %s)' % (stu,threading.current_thread().name))
def process_thread(name):
    #绑定 ThreadLocal 的 student
    local_school.student = name
    process_student()

t1 = threading.Thread(target=process_thread,args=('XiaoMing',),name='Thread-A')
t2 = threading.Thread(target=process_thread,args=('Jack',),name='Thread-B')
t1.start()
t2.start()
t1.join()
t2.join()
# 这种方式不知道为啥，总有一种随地大小便的感觉。
```
* ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。
* 计算密集型任务对代码的执行速度要求高，依赖 CPU 的执行速度 最好用高效率语言编写。 IO 密集型任务 依赖IO IO速度远慢于 CPU 可以使用方便的脚本语言编写。

09. 分布式进程 python 提供 QueueManager 把 Process 分布到多台机器上。封装了网络通信的过程，上层使用 Queue共享资源。
```py
# task_master.py
import random,time,queue
from multiprocessing.managers import BaseManager

# 发送任务的队列
task_queue = queue.Queue()
# 接收结果的队列
result_queue = queue.Queue()

# 从 BaseManager 继承的 QueueManager
class QueueManager(BaseManager):
    pass

# 把两个 Queue 注册到网络上
QueueManager.register('get_task_queue',callable=lambda:task_queue)
QueueManager.register('get_result_queue',callable=lambda:result_queue)
#绑定端口 5000 设置验证码 'abc'
manager = QueueManager(address = ('',5000),authkey=b'abc')
# 启动 Queue
manager.start()
# 获得通过网络访问的 Queue 对象
task = manager.get_task_queue()
result = manager.get_result_queue()
# 丢几个任务进去 
for i in range(10):# 不是我说，python 的 for 循环就一 SB
    n = random.randint(0,10000)
    print('Put task %d...' % n)
    task.put(n)
# 从result_queue 读取结果
print('Try get results...')
for i in range(10):
    r = result.get(timeout = 10)
    print('result: %s',r)
# 关闭
manager.shutdown()
print('master exit')
```
```py
# task_worker.py
import time,sys,queue
from multiprocessing.managers import BaseManager
# 创建类似的 QueueManager
class QueueManager(BaseManager):
    pass
# 由于这个 QueueManager 只从网络上获取 Queue，所以注册时只提供名字
QueueManager.register('get_task_queue')
QueueManager.register('get_result_queue')

# 连接到服务器
server_addr = '127.0.0.1'
print('Connect to server %s...' % server_addr)
# 端口和验证码要与主机一致
m = QueueManager(address = (server_addr,5000),authkey=b'abc')
# 从网络连接
m.connect()
# 获取 Queue 对象
task = m.get_task_queue()
result = m.get_result_queue()
# 从 task 队列获取任，并把结果写入 result 队列
for i in range(10):
    try:
        n = task.get(timeout=1)
        print('run task %d * %d...' % (n,n))
        r = '%d * %d = %d' % (n,n,n*n)
        time.sleep(1)
        result.put(r)
    except Queue.Empty:
        print('task queue is empty')
# 处理结束
print('work exit.')
```
* python BaseManager 对数据网络同步做了较好的封装
* 在两台电脑上测试了 task 和 worker

10. 正则表达式 用一次忘一次 哈哈哈哈 下次需要用到的时候再说吧。可以找时间封装 或者保存一些常用的正则表达式。

# [2017-07-14 继续复习 python]

01. 常用模块
* datetime 需要 from datetime import datetime

```py
from datetime import datetime
now = datetime.now() # 返回一个 datetime 对象 年月日时分秒毫秒
print(now) # 2017-07-14 10:03:05.791305

# 创建时间对象至少需要传入年月日三个参数，后边的参数默认为0
dt = datetime(2017,1,1,12,0,0)
print(dt) # 2017-01-01 12:00:00
dt = datetime(2017,9,1)
print(dt) # 2017-09-01 00:00:00

# 转换为时间戳
dt = datetime.now()
timestamp = dt.timestamp() # 毫秒数用小数表示 需要注意与其他语言的同步问题
print(timestamp)
# 时间戳转换为 datetime
t = 1499997785.791305
print(datetime.fromtimestamp(t)) # 转换为本地时间 2017-07-14 10:03:05.791305
print(datetime.utcfromtimestamp(t)) # 转换为 utc 时间 2017-07-14 02:03:05.791305

# 字符串转换为 datetime
cday = datetime.strptime('2017-7-14 10:05:55','%Y-%m-%d %H:%M:%S')
print(cday) # 2017-07-14 10:05:55
# datetime 转换为字符串
now = datetime.now()
print(now.strftime('%a,%b %d %H:%M')) # Fri,Jul 14 10:03

# datetime 的加减 需要 import timedelta
from datetime import datetime,timedelta
now = datetime.now()
now + timedelta(hours=10)
now - timedelta(days=1)
now + timedelta(days=2,hours=1)
```
* collections Python 的内建集合模块 提供很多有用的集合类

```py
# namedtuple 给 tuple 起一个名字
from collections imoport namedtuple
Point = namedtuple('Point',['x','y'])
p = Point(5,5)
p.x,p.y # (5,5)
type(p) # <class '__main__.Point'>
isinstance(p,Point) # True
isinstance(p,tuple) # True
# 定义一个圆圈
Circle = namedtupel('Circle',['x','y','r'])

# deque 高效实现插入和删除的双向列表 除支持 append() pop() 外 还支持 appendleft() popleft()
from collections import deque
q = deque(['a','b','c'])
q.append('X')
q.appendleft('y')
print(q) # deque(['y', 'a', 'b', 'c', 'X'])

# defaultdict 使用 dict 时，如果key不存在会抛出 KeyError defaultdict 可以设置 key 不存在时返回默认值
from collections import defaultdict
dd = defaultdict(lambda:'N/A') # defaultdict 的参数是一个函数
dd['key'] # 'N/A'

# OrderedDict 有插入顺序信息的 Dict
# Counter 计数器，可以统计字符出现次数
from collections import Counter
c = Counter()
for ch in 'programming':
    c[ch] = c[ch] + 1
print(c) # Counter({'r': 2, 'g': 2, 'm': 2, 'p': 1, 'o': 1, 'a': 1, 'i': 1, 'n': 1})
# Counter 实际上就是 value 是一个数字的字典，搞毛。。
```

02. base64 一种编码方式 常用于 cookie url 的编码

```py
import base64
base64.b64encode(b'HelloWorld') # b'SGVsbG9Xb3JsZA=='
base64.b64decode(b'SGVsbG9Xb3JsZA==') # b'HelloWorld'
base64.b64encode(b')\xe5\x9e\x8b\xef\xbf') # b'KeWei++/'
base64.urlsafe_b64encode(b')\xe5\x9e\x8b\xef\xbf') # b'KeWei--_'
base64.urlsafe_b64decode(b'KeWei--_') # b')\xe5\x9e\x8b\xef\xbf'
```
03. struct 模块用于解决 bytes 和其他二进制数据类型的转换 使用要规定一下格式。

04. hashlib 提供了常见的摘要算法 例如 MD5 SHA1 等等。

```py
# 计算字符串的 MD5
import hashlib

md5 = hashlib.md5()
md5.update('this is a secret sentence'.encode('utf-8'))
print(md5.hexdigest()) # 3213547ddfcf410eef5061e13450090b

# 如果数据量大 可以分块多次调用 update()
md5 = hashlib.md5()
md5.update('this is the first sentence'.encode('utf-8'))
md5.update('this is the second sentence'.encode('utf-8'))
print(md5.hexdigest()) # d8584ba8b3e1e951f2a7f6430a39bf52

# SHA1 的使用方式与 md5 类似
sha1 = hashlib.sha1()
sha1.update('this is the first sentence.'.encode('utf-8'))
sha1.update('this is the second sentence.'.encode('utf-8'))
print(sha1.hexdigest()) # 3f1faca3f8765a98cb18d2ea8a72d1d4ae0c4b95
```
* 在设计用户名密码存储的时候，可以考虑使用密码加用户信息的的 ‘加盐’ 方式 防止碰撞和被黑

05. itertools 模块提供了非常有用的用语操作迭代器对象的函数

```py
# itertools 中几个‘无限’迭代器
import itertools
natuals = itertools.count(1)
for n in natuals:
    print(n) # 打印所有的自然数 根本停不下来

# 循环打印字符串
cs = itertools.cycle('ABC')
for c in cs:
    print(c) # 循环打印所有字符串 根本停不下来

# repeat()  可以将一个元素无限重复下去 第二个参数可以指定重复的次数
ns = itertools.repeat('A')
for n in ns:
    print(n)

# 可以通过 take while() 函数限定截取范围
natuals = itertools.count(1)
ns = itertools.takewhile(lambda x: x <= 10,natuals)
list(ns) # [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

# chain() 可以把一组迭代对象串联起来 形成一个更大的迭代器
for c in itertools.chain('ABC','DEF'):
    print(c)

# groupby() 把迭代器中相邻的重复元素挑出来放在一起

for key,group in itertools.groupby('AAABBBCCAAA'):
    print(key,list(group))

>>>
A ['A', 'A', 'A']
B ['B', 'B', 'B']
C ['C', 'C']
A ['A', 'A', 'A']

# 可以穿入一个函数作为分组判断 也就是 key 参数的作用
for key,group in itertools.groupby('AaaBBbcCAAa',lambda c:c.upper()):
    print(key,list(group))

>>>
A ['A', 'a', 'a']
B ['B', 'B', 'b']
C ['c', 'C']
A ['A', 'A', 'a']
```

06. contextlib
* python 中为了正确关闭打开的文件可以使用 try...finally 和 with 语句。实际上实现了上下文管理的对象都可以使用 with 语句。
```py
# 实现上下文管理是通过 __enter__ 和 __exit__ 这两个方法实现的。
class Query(object):
    def __init__(self,name):
    self.name = name

    def __enter__(self):
        print('Begin')
        return self
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            print('Error')
        else:
            print('End')

    def query(self):
        print('start query %s...' % self.name)


with Query('XiaoMing') as q:
    q.query()
```
* contextlib 提供了更简单的写法 @contextmanager 的执行顺序
from contextlib import contextmanager

class Query(object):
    def __init__(self,name):
        self.name = name

    def query(self):
        print('query info about %s...' % self.name)

@contextmanager
def create_query(name):
    print('Begin')
    q = Query(name)
    yield q
    print('End')

with create_query('XiaoMing') as q: # 这种方式不会影响原有的类 相当于对原有的类做了一些加工
    q.query()
```
* 1 执行 yield 之前的语句 2 执行 with 语句内的内容 3 执行 yield 之后的语句 可以利用这个特性打印方法执行日志，在方法前后各执行一些东西。

* @closing 可以将对象变为上下文对象。
```py
from contextlib import closing
from urllib.request import urlopen

with closing(urlopen('https://www.python.org')) as page:
    for line in page:
        print(line)
# 不知道干了啥，好像是 closing 之后就可以用 with 了 但是还没搞明白 with 帮 urlopen 做了什么。

07. XML 操作 XML 可以使用 DOM 方法和 SAX 方法。DOM方法需要把内容加载到内存，解析慢，但是可以任意遍历树的节点。SAX 占用内存小，速度快，需要我们自己处理事件。
```py
from xml.parsers.expat import ParserCreate

class DefaultSaxHandler(object):
    def start_element(self,name,attrs):
        print('sax:start_element:%s,attrs:%s' % (name,str(attrs)))

    def end_element(self,name):
        print('sax:end_element:%s' % name)
    def char_data(self,text):
        print('sax:char_data:%s' % text)

xml = r'''<?xml version="1.0"?>
<ol>
<li><a href="/python">Python</a></li>
<li><a href="/ruby">Ruby</a></li>
</ol>
'''

handler = DefaultSaxHandler()
parser = ParserCreate()
parser.StartElementHandler = handler.start_element
parser.EndElementHandler = handler.end_element
parser.CharacterDataHandler = handler.char_data
parser.Parse(xml)
```

08. HTMLParser HTML 不是严格的 XML。python 提供了 HTMLParser 可以方便的解析 HTML
```py HTMLParser 示例
from html.parser import HTMLParser
from html.entities import name2codepoint

class MyHTMLParser(HTMLParser):
    def handle_starttag(self,tag,attrs):
        print('<%s>' % tag)
    def handle_endtag(self,tag):
        print('</%s>' % tag)
    def handle_startendtag(self,tag,attrs):
        print('<%s/>' % tag)
    def handle_data(self,data):
        print(data)
    def handle_comment(self,data):
        print('<!--',data,'-->')
    def handle_entityref(self,name):
        print('&%s;' % name)
    def handle_charref(self,name):
        print('&#%s' % name)

parser = MyHTMLParser()
parser.feed('''<html>
<head></head>
<body>
<!-- test html parser -->
<p>Some <a href=\"#\">html</a> HTML&nbsp;tutorial...<br>END</p>
</body></html>''')

# [2017-07-15 继续复习 python]

01. urllib 提供了 url web 请求相关的内容。

* GET 请求
```py
from urllib import request

with request.urlopen('https://www.bing.com') as f:
    data = f.read()
    print('Status:',f.status,f.reason)
    for k,v in f.getheaders():
        print('%s:%s' % (k,v))
    print('Data:',data.decode('utf-8'))

# 如果要模拟浏览器 需要设置 httpHeader

req = request.Request('https://www.bing.com')
req.add_header('User-Agent', 'Mozilla/6.0 (iPhone; CPU iPhone OS 8_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/8.0 Mobile/10A5376e Safari/8536.25')
with request.urlopen(req) as f:
    print('Status:',f.status,f.reason)
    for k,v in f.getheaders():
        print('%s:%s' % (k,v))
    print('Data:',f.read().decode('utf-8'))
```

* POST 请求 POST 请求的参数以 bytes 形式

from urllib import request,parse

print('登录微博')
account = input('账号:')
pwd = input('密码:')
login_data = parse.urlencode([
    ('username',account),
    ('password',pwd),
    ('entry','mweibo'),
    ('client_id',''),
    ('savestate','1'),
    ('ec',''),
    ('pagerefer','https://passport.weibo.cn/signin/welcome?entry=mweibo&r=http%3A%2F%2Fm.weibo.cn%2F')
])

req = request.Request('https://passport.weibo.cn/sso/login')
req.add_header('Origin','https://passport.weibo.cn')
req.add_header('User-Agent', 'Mozilla/6.0 (iPhone; CPU iPhone OS 8_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/8.0 Mobile/10A5376e Safari/8536.25')
req.add_header('Referer', 'https://passport.weibo.cn/signin/login?entry=mweibo&res=wel&wm=3349&r=http%3A%2F%2Fm.weibo.cn%2F')

with request.urlopen(req,data=login_data.encode('utf-8')) as f:
    print('Status:',f.status,f.reason)
    for k,v in f.getheaders():
        print('%s:%s' % (k,v))
    print('Data:',f.read().decode('utf-8'))

* proxyHandler urllib 中的 ProxyHandler() 可以用来完成代理相关的操作。

* 今天上午去了趟驾校 教练脾气好大。
* 更新放在单位电脑了 周一同步。

# [2017-07-17 继续复习 python]
01. 常用第三方模块 python 中的第三方模块需要在 python package index 上注册，注册后可以使用 pip + 模块名安装。
* Pillow 是 python 中的图像处理库，可以用于帮助处理图像，虚化，画图生成验证码等等。
* GUI python 支持多种图像界面库 包括 TK wxWidgets Qt GTK。可以做一些简单通用的界面。如果做复杂的界面还是需要使用原生语言。

02. 网络编程 python 提供了简单的 API 进行网络编程。
* socket 客户端流程 创建socket-设置连接-发送数据-接收数据-关闭连接-解析数据 (解析数据可能和接收数据同步进行)
```py
import socket
# 创建socket
s = socket.socket(socket.AF_INET,socket.SOCK_STREAM) # IPV4 面向流的 TCP 协议
# 设置连接
s.connect(('www.bing.com',80))
# 发送数据
s.send(b'GET / HTTP/1.1\r\nHost:www.bing.com\r\nConnection:close\r\n\r\n')
# 接收数据
buffer = []
while True:
    d = s.recv(1024)
    if d:
        buffer.append(d)
    else:
        break
data = b''.join(buffer)
# 关闭连接
s.close()
# 解析数据
header,html = data.split(b'\r\n\r\n',1)
print(header.decode('utf-8'))
print('======')
print(html)
# 把接收的数据写入文件
with open('bing.html','wb') as f:
    f.write(html)
```
* socket 服务端流程 
```py
import socket
import threading,time


def tcplink(sock,addr):
    print('Accept new connection from %s:%s...' % addr)
    sock.send(b'Welcome')
    while True:
        data = sock.recv(1024)
            time.sleep(1)
        if not data or data.decode('utf-8') == 'exit':
            break
        sock.send(('Hello,%s' % data.decode('utf-8')).encode('utf-8'))
    sock.close()
    print('Connection from %s:%s closed...' % addr)
    print('====== ===== ===== =====')
    print('')

# 创建 socket
s = socket.socket(socket.AF_INET,socket.SOCK_STREAM)
# 监听端口
s.bind(('127.0.0.1',9999))
s.listen(5) # 参数为等待连接的最大数量
print('Waiting for connection...')
while True:
    # 接收连接
    sock,addr = s.accept()
    # 创建新的线程处理 TCP 连接
    t = threading.Thread(target=tcplink,args=(sock,addr))
    t.start()
```

# [2017-07-18 继续复习 python]

01. UDP 面向无连接
* UDP server 流程 创建socket 绑定端口 接收数据 然后就不管了
```py
import socket

s = socket.socket(socket.AF_INET,socket.SOCK_DGRAM)
# 绑定端口
s.bind(('127.0.0.1',9999))

print('Bind UDP on 9999...')
while True:
    data,addr = s.recvfrom(1024)
    print('Receive from %s:%s' % addr)
    s.sendto(b'Hello,%s!' %  data,addr)
```
* UDP client 创建socket 发送数据
``` py
socket = socket.socket(socket.AF_INET,socket.SOCK_DGRAM)
for data in [b'Michael',b'Tracy',b'Sarah']:
    # 发送数据
    s.sendto(data,('127.0.0.1',9999))
    # 接收数据
    print(s.recv(1024).decode('utf-8'))
s.close()
```

02. 电子邮件
* MUA Mail User Agent 邮件用户代理 电子邮件客户端软件要发送邮件到 MUA
* MTA Mail Transfer Agent 邮件传输代理 Email 服务提供商 用于转发电子邮件
* MDA Mail Delivery Agent 邮件投递代理 最终保存接收方邮件的地方。收件人需要主动从 MDA 获取邮件
* 一封邮件的旅程
```py
# 发件人 -> MUA -> MTA ->MTA -> 若干个 MTA -> MDA <- MUA <- 收件人
```
* SMPT Simple Mail Transfer Protocol 简单邮件传输协议
* POP Post Office Protocol 
* IMAP Internet Message Access Protocol
* 发送邮件  python 的 email 模块用于处理发送邮件。发送邮件需要设置好相应的数据格式，数据头，数据MIMEType等，可设置发送文字 html文件等。现在各邮件服务商都要求使用 SSL。
* 接收邮件 主要是用到 poplib

03. SQLite SQLite 是 C 编写的轻量级数据库，经常被集成到各种应用程序中。
* python 中使用 SQLite 简要流程
```py
import sqlite3

# 连接到 SQLite 数据库
# 数据库文件是 test.db
# 如果文件不存在 会自动在当前目录创建
conn = sqlite3.connect('test.db')
# 创建一个 Cursor:
cursor = conn.cursor()
# 执行一条 SQL 语句 创建 user 表
 cursor.execute('create table user (id varchar(20) primary key,name varchar(20))')
# 继续执行一条 SQL 语句，插入一条记录
cursor.execute('insert into user (id,name) values(\'1\',\'Michael\')')
cursor.execute('select * from user')
result = cursor.rowcount
print(result)
result = cursor.fetchall()
print(result)

cursor.close()
conn.commit()
conn.close()

# 使用 python 的 DB-API 需要搞清楚 Connection 和 Cursor 对象 打开后一定记得关闭 就可以放心使用
```

04. MYSQL 广泛使用的数据库服务器，能承受高并发访问，同时占用内存也远远大于 SQLite
* MYSQL 安装之后需要精心的配置。配置完成后，为配合 python 使用，需要安装驱动
```py
# 安装 -mysql-connector-python 驱动
$ pip install mysql-connector-python --allow-external mysql-connector-python
# 如果安装失败，就试试别的驱动，当时装的是 pymysql。
```py
# 需要安装 pymysql
# pip3 install pymysql
# 获取 conn 需要先启动 mysql mysql -u root -p 并选中 database
# 创建 conn
import pymysql

conn = pymysql.Connect(user='root',password='123456',db='zcbase')

cursor = conn.cursor()
cursor.execute('set character_set_results=utf8')
cursor.execute('select * from persons')
result = cursor.fetchall()
print(result)
```
05. SQLAlchemy 是 python 中的一个 ORM 框架。

# [2017-07-19 继续复习 python]
01. WSGI(Web Server Gateway Interface) Web 服务器网关接口 负责生成最终的 HTML
```py
# hello.py
def application(environ,start_response):
    print(environ)
    start_response('200 OK',[('Content-Type','text/html')])
    body = '<h1>Hello, %s</h1>' % (environ['PATH_INFO'][1:] or 'web')
    return [body.encode('utf-8')]
```
* start_response('200 OK',[('Content-Type','text/html')]) 发送 http header。header只能发送一次，所以这个函数只能调用一次，参数是HTTP相应码和 HTTP header 组成的list。
* 函数返回值返回 http body。

02.applicatiion() 函数必须由 WSGI 服务器来调用， python 内置的 WSGI 模块是 wsgiref。wsgiref 是一个参考实现，意思是实现符合WSGI标准，但是不考虑运行效率。
```py
# server.py
# 从 wsgiref 模块导入:
from wsgiref.simple_server import make_server
# 导入我们自己编写的 application 函数：
from hello import application

# 创建一个服务器，IP 地址为空，端口号是 8000，处理函数是 application：
httpd = make_server('',8000,application)
print('Serving HTTP on port 8000...')
# 开始监听 HTTP 请求：
httpd.serve_forever()
```
* applicaiton() 方法中的 environ 参数保存着访问信息。
environ['PATH_INFO'][1:] 可以把路径信息提取出来。 

03. python 提供了大量的 web 框架，将 URL 映射到具体的执行函数。
* Flask 需要 pip3 install flask
* Flask 默认绑定 5000 端口
```py
# flask_app.py
from flask import Flask
from flask import request

app = Flask(__name__)

@app.route('/',methods=['GET','POST'])
def home():
    return '<h1>Home</h1>'

@app.route('/signin',methods=['GET'])
def signin_form():
    return '''<form action="/signin" method="post">
            <p><input name="username"></p>
            <p><input name="password" type="password"></p>
            <p><button type="submit">Sign In</button></p>
            </form>'''

@app.route('/signin',methods=['POST'])
def signin():
    # 需要从 request 对象读取表单内容
    if request.form['username'] == 'admin' and request.form['password']=='password':
        return '<h3>Hello,admin</h3>'
    return '<h3>Bad username or password</h3>'

if __name__ == '__main__':
    app.run()
```
* flask 通过装饰器在内部自动把 URL 和函数关联起来。

04. python 其他的 Web 框架
* Django：全能型Web框架；
* web.py：一个小巧的Web框架；
* Bottle：和Flask类似的Web框架；
* Tornado：Facebook的开源异步Web框架。

05. 使用模板 模板就是连接 web框架和具体的html页面的工具。处理参数的传递。
```py
from flask import Flask,request,render_template
print(__name__)
app = Flask(__name__)

@app.route('/',methods=['GET','POST'])
def home():
    return render_template('home.html')

@app.route('/signin',methods=['GET'])
def signin_form():
    return render_template('form.html')

@app.route('/signin',methods=['POST'])
def signin():
    username = request.form['username']
    password = request.form['password']
    if username == 'admin' and password == 'password':
        return render_template('signin-ok.html',username=username)
    return render_template('form.html',message='Bad username or password',username=username)

if __name__ == '__main__':
    app.run()
```
* Flask 支持的模版是 jinja2 所以需要安装 jinja2 pip3 install jinja2
```html
<! --home.html -->
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Home</title>
</head>
<body>
    <h1 style="font-style:italic">Home</h1>
</body>
</html>
```
```html
<! --form.html -->
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Please Sign In</title>
</head>
<body>
    {% if message %}
    <p style="color:red">{{message}}</p>
    {% endif %}
    <form action="/signin" method="post">
        <legend>Please sign in:</legend>
        <p><input name="username" placeholder="Username" value = "{{username}}"></p>
        <p><input name="password" placeholder="Password" type="password"></p>
        <p><button type="submit">Sign In</button></p>
    </form>
</body>
</html>
```

```html
<!-- signin-ok.html -->
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Welcome, {{username}}</title>
</head>
<body>
    <p>Welcome,{{username}}</p>
</body>
</html>
```
* 模板需要放到 templates 目录下， templates和 app.py 在同级目录下。
* 登录前和成功后，浏览器收到的html文件
```py

<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8">
        <title>Please Sign In</title>
    </head>
    <body>
        <form action="/signin" method="post">
            <legend>Please sign in:</legend>
            <p><input name="username" placeholder="Username" value = ""></p>
            <p><input name="password" placeholder="Password" type="password"></p>
            <p><button type="submit">Sign In</button></p>
        </form>
    </body>
</html>
```
```html
<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8">
        <title>Welcome, admin</title>
    </head>
    <body>
        <p>Welcome,admin</p>
    </body>
</html>
```

06. 协程(Coroutine) 协程又称微线程
* 协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候在返回来接着执行。
* python 中的协程是通过 generator 实现的。
```py
def consumer():
    r = ''
    print('[CONSUMER] Start Consumer...')
    while True:
        n = yield r # 这句话的意思是，在切换到这里到时候，把 send 里到值取出来，赋值给 n
        if not n:
            return
        print('[CONSUMER] Consuming %s and return result %s...' % (n,n * n))
        r = '200 OK'

def produce(c):
    print('[PRODUCER] Before send None')
    c.send(None)
    print('[PRODUCER] After send None')
    n = 0
    while n < 5:
        n = n+1
        print('[PRODUCER] Producing %s ...' % n)
        r = c.send(n)
        print('[PRODUCER] Consumer return %s' % r)
    c.close()

c = consumer()
produce(c)

results 
[PRODUCER] Before send None
[CONSUMER] Start Consumer...
[PRODUCER] After send None
[PRODUCER] Producing 1 ...
[CONSUMER] Consuming 1 and return result 1...
[PRODUCER] Consumer return 200 OK
[PRODUCER] Producing 2 ...
[CONSUMER] Consuming 2 and return result 4...
[PRODUCER] Consumer return 200 OK
[PRODUCER] Producing 3 ...
[CONSUMER] Consuming 3 and return result 9...
[PRODUCER] Consumer return 200 OK
[PRODUCER] Producing 4 ...
[CONSUMER] Consuming 4 and return result 16...
[PRODUCER] Consumer return 200 OK
[PRODUCER] Producing 5 ...
[CONSUMER] Consuming 5 and return result 25...
[PRODUCER] Consumer return 200 OK
```
* 子程序就是协程的一种特例

07. asyncio 异步IO
* yield from asyncio.sleep(1) 也是一个coroutine，所以线程不会等待 asyncio.sleep(),而是直接中断并执行下一个消息循环。
```py
import asyncio

@asyncio.coroutine
def hello():
    print('Hello,world!')
    r = yield from asyncio.sleep(1)
    print('Hello,again')

loop = asyncio.get_event_loop()
loop.run_until_complete(hello())
loop.close()
```
```py
import asynic
import threading
@asynio.coroutine
def hello():
    print('Hello,world (%s)' % threading.currentThread())
    yield from asyncio.sleep(1)
    print('Hello,again (%s)' % threading.currentThread())

loop = asyncio.get_event_loop()
tasks = [hello(),hello()]
loop.run_unitl_complete(asyncio.wait(tasks))
loop.sleep()

# 结果  先打印
Hello,world! (<_MainThread(MainThread, started 140736324834240)>)
Hello,world! (<_MainThread(MainThread, started 140736324834240)>)
# 一秒之后打印
Hello,again! (<_MainThread(MainThread, started 140736324834240)>)
Hello,again! (<_MainThread(MainThread, started 140736324834240)>)
# 可以看到，都在一个线程之中
```
* 协程访问三个网址的 header
** yield from 关键字的功能还需要理解
```py
mport asyncio

@asyncio.coroutine
def wget(host):
    print('wget %s...' % host)
    connect = asyncio.open_connection(host,80)
    reader,writer = yield from connect
    header = 'GET / HTTP/1.0\r\nHost:%s\r\n\r\n' % host
    writer.write(header.encode('utf-8'))
    yield from writer.drain()
    while True:
        line = yield from reader.readline()
        if line == b'\r\n':
        break
    print('%s header > %s' % (host,line.decode('utf-8').rstrip()))
    writer.close()

loop = asyncio.get_event_loop()
tasks = [wget(host) for host in ['www.sina.com.cn','www.sohu.com','www.163.com']]
loop.run_until_complete(asyncio.wait(tasks))
loop.close()
```
08. async/await 
* @asyncio.coroutine 可以把一个 generator标记为 coroutine类型，然后再coroutine内部调用yield from 调用另一个coroutine实现异步操作。
* 为了简化并更好的标记异步IO，python3.5开始引入了新语法 async 和 await
** 把 @asyncio.coroutine 替换为 async
** 把 yield from 替换为 await
```py
async def hello():
    print('hello,world')
    r = await asyncio.sleep(1)
    print('hello,again')
```
09. asyncio 用在 web服务器，可以用单线程实现多用户的高并发支持。
* asyncio 实现了 TCP UDP SSL 等协议，aiohttp 则是基于 asyncio实现的 HTTP 框架 需要 pip3 install aiphttp
```py
import asyncio
from aiohttp import web

async def index(request):
    await asyncio.sleep(0.5)
    return web.Response(body=b'<h1>Index</h1>',content_type='text/html')

async def hello(request):
    await asyncio.sleep(0.5)
    text = '<h1>hello,%s</h1>' % request.match_info['name']
    return web.Response(body=text.encode('utf-8'),content_type='text/html')

async def init(loop):
    app = web.Application(loop = loop)
    app.router.add_route('GET','/',index)
    app.router.add_route('GET','/hello/{name}',hello)
    srv = await loop.create_server(app.make_hander(),'127.0.0.1',8000)
    print('Server started at http://127.0.0.1:8000')
    return srv

loop = asyncio.get_event_loop()
loop.run_until_complete(init(loop))
loop.run_forever()
```
# [2017-07-22 继续复习 python]
因为KW捣乱 今天终于可以不学习了 开心（KW说的）

# [2017-08-07 CMake]
01. 使用 CMake 编译文件。
* 简单看了下 CMake 的工作方式，感觉还是要有一个专门的编译工具来编写调试源码。不知道 tensorflow 和其他一些开源代码是怎么做的。可能是用的他们内部的工具。

# [2017-08-08 CMake]
01. 使用CMake 在编辑文件的时候，还是需要使用专门的编译器编译文本，在使用普通的文本编译器的时候，有时会出现"" 中英文不匹配的问题，造成奇怪的处理错误。

# [2017-09-22 开始一个新的笔记 利用python进行数据分析 和git上的pydata配合使用]
01. 列表生成式的使用需要转变思路，多写几个形成肌肉记忆。
```py
path = "aaa.txt"
records = [json.load(line) for line in open(path)]
time_zone = [rec['tz'] for rec in records if 'tz' in rec]
```
02. default dict 带有默认数值的dict
```py
from collections import defaultdict
def get_count2(sequence):
    counts = defaultdict(int)
        for x in sequence:
            counts[x] += 1
        return counts
```
Counter 可以更方便的统计出现次数
```py
from collections import Counter
counts = Counter(time_zones)
result = counts.most_common(10)
```
03. pandas 是一个开源库 python 开发 《利用python进行数据分析》的作者主导开发的。依赖numpy使用。 numpy 是C语言开发的强大的接口工具。
* DataFrame 是 pandas 中最重要的数据结构。
plot 画图需要 调用 plt.show() 才会显示
```py
import matplotlib.pyplot as plt
...
balabala
...
plt.show()
```

# [2017-09-25 pandas学习 天下武功唯快不破]
01. pandas 导入数据列表
```py
import pandas as pd
unames = ['user_id','gender','age','occupation','zip']
# 这里补充 engine='python' 参数 可以消除C regex 的 warnning
users = pd.read_table('/Users/AAA/pydata-book/ch02/movielens/users.dat',sep='::',header=None,names=unames,engine='python')
```

02. help(pd.pivot_table) 可以获得方法的帮助信息 dir(pd.pivot_table)可以获得对象支持的方法的信息。

03. pd.concat() 把多个frame组合在一起，ignore_index=True 忽略行号。
04. 在变量或者模块名称后加上？可以打印相关信息。 ?? 可以打印源代码如果可能的话。
```py
b = [1,2,3]
b?
Type:        list
String form: [1, 2, 3]
Length:      3
Docstring:
list() -> new empty list
list(iterable) -> new list initialized from iterable's items
```
05. 通配符 * 配合使用匹配相似的名称
```py
In [1]: np.*load*?
np.__loader__
np.load
np.loads
np.loadtxt
np.pkgload
```
06. %run 在IPython会话环境中，所有文件都可以通过%run命令当作Python程序来运行。文件中的变量和import语句会保留在当前会话中。
```py
%run ipython_script_test.py
```
07. 执行剪切板中的内容 %paste 或者 %cpaste 。建议一直使用%cpaste
```py
a = 1
b = 2
c = a+b
print(c)
```
08. 一些有用的快捷键
Ctrl -A 光标移动到行首
Ctrl-E 光标移动到行尾
Ctrl-K 删除光标开始到行尾的文本
Ctrl-U 清除开始到光标处的文本
Ctrl-L清屏

09. 魔术命令 （Magic Command）为常见任务提供便利
%timeit 可以检测任意python语句的执行时间。
```py
import numpy as np
a = np.random.randn(100,100)
%timeit np.dot(a,a)
The slowest run took 662.16 times longer than the fastest. This could mean that an intermediate result is being cached.
10000 loops, best of 3: 31.6 µs per loop
```
* 大部分魔术命令又一些命令行选项，可以使用？查看选项
```py
%reset?
```
魔术命令默认是可以不带%使用的，只要没有定义与其同名的变量即可，这个技术叫做automagic 可以使用%automagic打开或关闭。
```py
# 常用的IPython魔术命令
%quickref 显示IPython 的快速参考
%magic 显示所有魔术命令的详细文档
%debug 从最新的异常跟踪的底部进入交互式调试器
%hist 打印命令的输入（可选输出）历史
%pdb 在异常发生后自动进入调试器
%paste 执行剪贴板中的Python代码
%cpaste 打开一个特殊提示符一边手工粘贴待执行的Python代码
%reset 删除interactive命名空间中的全部变量／名称
%page OBJECT 通过分页器打印输出OBJECT
%run 执行python脚本文件
%time statement 报告statement执行时间
%timeit statement 多次执行statement 以计算系统平均执行时间
%xdel varialbe 删除variable，并尝试清除其在IPython中的对象上的一切引用
```
10. 在启动IPython时加上 —pylab标记来集成matplotlib
11. _ 和 __分别保存了最近的两个计算结果。如果忘记赋值给变量可以用这个读出来。
12. 与日志相关的命令
```py
%logstart 开始记录日志
%logoff
%logon
%logstate
%logstop
```
13. IPython 打印对象 其实是显示 __repr__方法返回的字符串。可以定制
```py
def __repr__(self):
      return ‘this is %s’ % self.message
```
 
14. Numpy(Numerical Python) 是高性能科学计算和数据分析的基础包。
* ndarray，一个具有矢量算术和复杂广播能力的快速且节省空间的多维数组。
* 用于对整组数据进行快速运算的标准数学函数。
* 用于读写磁盘数据的工具以及用于操作内存映射文件的工具。
* 线性代数 随机数生成以及傅立叶变换的功能。
* 用于集成C C++ Fortran等语言编写的代码的工具。
* NumPy 提供了一个简单易用的 C API，因此很容易将数据传递给由低级语言编写的外部库，外部库也能以NumPy数组的形式将数据返回给Python。
15. Numpy 本身没有提供多么高级的数据分析功能，理解NumPy数组以及面向数组的计算将有助于更加高效的使用诸如pandas之类的工具。

# [2017-09-26 利用 python 进行数据分析 numpy]
01. ndarray numpy 中的多维数组
```py
# 创建数组 -从list 创建数组
data1 = [1,2,3]
arr1 = np.array(data1)
data2 = [[1,2,3],[4,5,6]]
arr2 = np.array(data2)
arr2.ndim # 2
arr2.shape # (2,4)
np.arange(15) # numpy的range
asarray
ones，ones_like
zeros,zeros_like
empty,empty_like
eye, identity # N*N 单位矩阵
arr3 = np.array([1,2,3],dtype=float64) # 指定数据类型

```
02. 类型推断
* 如果没有显式制定，np.array 会创世为创建的这个数组推断出一个较为合适的数据类型。
* 类型转换
```py
# 可以通过astype显式转换类型。注意数据截断
arr = np.array([1,2,3,4,5])
arr.dtype # int64
float_arr = arr.astype(np.float64)
float_arr.dtype # float64
# astype 也可以把数字转换为数值类型

```
03. 数组和标量之间的运算
* 大小相同的数组之间的运算会对应到元素之间的运算。
* 不同大小之间的数组运算叫做广播 broadcasting 后续介绍
* arr数组的切片是一个引用，对其的修改会反映到源数组上。
* 如果想要得到一个副本，需要使用arr[5:8].copy()方法。
04. 索引和切片
* 多维数组的切片得到的还是一个dnarray 如果需要副本需要copy 会有广播机制
* 切片是沿着多维数组的某一维度进行切片，都是统一的。
05. 布尔型索引
* 布尔型数组的长度必须跟被索引的轴长度一致。此外，还可以将布尔型数组和切片，整数，混合使用。
* 通过布尔型索引选取数组中的数据，总是创建数据的副本。即使返回一模一样的数组也是如此。
* python 中的 and 和 or 在布尔型数组中无效。
```py
names = np.array(['Bob','Joe','Will','Bob','Will','Joe','Joe'])
data = randn(7,4)
———————
data
array([[-0.54910643, -1.94454261, -0.91446588, -0.54232686],
       [ 0.90431567,  0.27737924,  0.02244441,  1.92119575],
       [-0.24816831,  0.52190193,  0.67697485,  1.18746317],
       [-0.11422256,  0.0254807 ,  0.60318349,  0.07973198],
       [-0.65968773,  0.35424598,  0.48108908, -1.15507434],
       [ 0.49463101, -0.62193634, -0.3358689 , -0.59763738],
       [-0.95526658,  0.34457363,  0.09158789, -1.43063909]])
———————
names == ‘Bob’ # array([ True, False, False,  True, False, False, False], dtype=bool)
data[names == ‘Bob’]
———
array([[-0.54910643, -1.94454261, -0.91446588, -0.54232686],
       [-0.11422256,  0.0254807 ,  0.60318349,  0.07973198]])
# 选取 data 中对应为True的行
———
* 可以使用切片和数字选取部分结果。
* 布尔逻辑可以使用 & | ！ - 等。
* python 中的 and 和 or 无效。
```
06. 花式索引（Fancy indexing）搞铲铲
* 花式索引总是将数据复制到新数组中。
```py
arr = np.empty()
for i in range(8):
	arr[i] = i

arr
———
array([[ 0.,  0.,  0.,  0.],
       [ 1.,  1.,  1.,  1.],
       [ 2.,  2.,  2.,  2.],
       [ 3.,  3.,  3.,  3.],
       [ 4.,  4.,  4.,  4.],
       [ 5.,  5.,  5.,  5.],
       [ 6.,  6.,  6.,  6.],
       [ 7.,  7.,  7.,  7.]])
———
arr[[4,0,3,6]]
——
array([[ 4.,  4.,  4.,  4.],
       [ 0.,  0.,  0.,  0.],
       [ 3.,  3.,  3.,  3.],
       [ 6.,  6.,  6.,  6.]])


arr = np.arange(32).reshape((8,4))
arr
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11],
       [12, 13, 14, 15],
       [16, 17, 18, 19],
       [20, 21, 22, 23],
       [24, 25, 26, 27],
       [28, 29, 30, 31]])

arr[[1,5,7,2],[0,3,1,2]]
# array([ 4, 23, 29, 10])
# (1,0),(5,3),(7,1),(2,2)

arr[[1,5,7,2]][:,[0,3,1,2]]
array([[ 4,  7,  5,  6],
       [20, 23, 21, 22],
       [28, 31, 29, 30],
       [ 8, 11,  9, 10]])

# 或者使用 np.ix_ 方法
arr[np.ix_([1,5,7,2],[0,3,1,2])]
———
array([[ 4,  7,  5,  6],
       [20, 23, 21, 22],
       [28, 31, 29, 30],
       [ 8, 11,  9, 10]])
```

07. 数组转置和轴对换
* reshape
* .T
* .transpose
* .swapaxes

08. 通用函数
* ufunc 是一种对ndarray中的数据执行元素级运算的函数，可以看成是简单函数（接受一个或多个标量，并产生一个或多个标量值）
09. 利用数组进行数据处理
* numpy数组提供将许多种数据处理任务表述为简洁的数组表达式。
* 用数组表达式可以代替循环的做法通常被称为矢量化。一般来说，矢量化数组运算要比等价的纯Python方式快上一两个数量级（真的假的。。。该不会是拿自己最快的和人家最慢的比吧。。。）

# [2017-09-27 利用 python 进行数据分析 numpy]
01. 将条件逻辑表述为数组运算。
```py
np.where(cond,arr1,arr2)
```
02. 数学和统计方法
* sum mean std var 既可以当作数组的实例方法调用，也可以当作顶级NumPy函数调用。
03. 排序
* NumPy 数组可以通过sort方法就地排序，会修改实例对象。或者使用NumPy顶级函数调用，会返回一个副本。
* sort方法可以指定排序的轴。

04. 唯一化以及其他的集合逻辑
```py
np.unique()
intersect1d(x,y)
union1d(x,y)
in1d(x,y)
setdiff1d(x,y)
setxor1d(x,y)
```
05. 读写文件
np.save 和 np.load 是读写磁盘数组数据的两个重要函数。
```py
arr = np.arange(10)
np.save(‘some_array’,arr)

np.load(‘some_array.npy’)
# np.savez() 可以将多个数组保存到一个压缩文件中。数组以关键字参数的形式传入。保存文件为 npz 文件。
# 加载npz文件后，会得到一个字典的对象。该对象会对各个数组进行延迟加载。
np.savez(‘array_archive.npz’,a= arr,b = arr)
arch = np.load(‘array_archive.npz’)
arch[‘b’]
```
06. 存取文本文件
* 主要介绍pandas中的read_csv和read_table函数。python中的文件读写函数很容易将新手搞晕。（他是这么说的。。回头看一下吧。）
* np.loadtxt 和 np.genformtxt 将数据加载到普通的NumPy中。

```py
!cat array_ex.txt # Linux 命令 查看txt文件
np.loadtxt(‘array_txt’,delimiter=‘,’) # np读入txt
np.savetxt 是相反的操作。
07. 线性代数
* x.dot(y) 相当于np.dot(x,y) 即矩阵的点积
* numpy.linalg中有一组标准的矩阵分解运算以及诸如求逆和行列式之类的东西。

08. 随机数生成
numpy的随机进行了优化，比python自带的随机快。
* 总之就是np.random 各种随机数，各种各样的。

09. 随机漫步和一次模拟多个随机漫步。
* 主要是要理解面向数组的思维方式，避免写循环。这样看起来似乎简洁一些。 但是循环还是隐藏在背后。

# [2017-09-29 利用 python 进行数据分析 pandas]

01. Series 类似于一维数组的对象。
```py
# 支持的操作
obj = Series([4,7,-5,3])
obj.values
obj.index

obj2 = Series([4,7,-5,3],index=[‘d’,’b’,’a’,’c’])
obj2.index
obj2.values
obj2[‘a’]
obj2[‘c’,’a’,’d’]
obj2[obj2>2]
obj2 * 2
np.exp(obj2)
```

02. 还可以将Series看作一个定长的有序字典。
```py
‘b’ in obj2 # True
‘e’ in obj2 # False
data = {‘Ohio’:35000,’Texas’:71000,’Oregon’:16000,’Utah’:5000}
obj3 = Series(sdata)
obj3
Out[335]: 
Ohio      35000
Oregon    16000
Texas     71000
Utah       5000
dtype: int64

states = [‘California’,’Ohio’,’Oregon’,’Texas’]
obj4 = Series(sdata,index=states)
obj4
Out[343]: 
California        NaN
Ohio          35000.0
Oregon        16000.0
Texas         71000.0
dtype: float64

# pandas 缺失值为NaN，成为missing 或者NA
pd.isnull(obj4)
pd.notnull(obj4)

Series也有类似的实例方法
obj4.isnull()
```

03. Series在算术运算中会自动对其不同索引的数据。
```py
obj3 + obj4
04. Series 有一个name属性 Series的索引值可以通过赋值修改
```py
obj4.name=‘population’
obj4.index.name=’state’

obj.index = [‘Bob’,’Steve’,’Jeff’,’Ryan’]
```
05. DataFrame 是一个表格型的数据结构，即有行索引也有列索引，可以被看作由Series组成的字典。DataFrame中的数据是以一个或多个二维块存放的，而不是列表／字典或者别的一维数据结构。
* 创建 DataFrame 最常用的一种是直接穿入一个由等长列表或者NumPy数组组成的字典。
```py
data = {'state':['Ohio','Ohio','Ohio','Nevada','Nevada'],
     ...: 'year':[2000,2001,2002,2001,2002],
     ...: 'pop':[1.5,1.7,3.6,2.4,2.9]}
frame = DataFrame(data)
frame
Out[358]: 
   pop   state  year
0  1.5    Ohio  2000
1  1.7    Ohio  2001
2  3.6    Ohio  2002
3  2.4  Nevada  2001
4  2.9  Nevada  2002

# 如果指定了列序列，则DataFrame的列就会按照指定的顺序进行排列。
DataFrame(data, columns = [‘year’,’state’,’pop’]) 

# 如果指定的列序列索引找不到数据，就会产生NA值。
frame = DataFrame(data,columns=['year','state','pp'])
Out[363]: 
   year   state   pp
0  2000    Ohio  NaN
1  2001    Ohio  NaN
2  2002    Ohio  NaN
3  2001  Nevada  NaN
4  2002  Nevada  NaN

# 通过类似字典标记的方式或者属性的方式，可以将DataFrame的列获取为一个Series
```py
frame[‘state’]
frame.state
# 返回的 Series 和 DataFrame 有相同的索引。且其 name 属性也已经被相应的设置好了。name 就是 key 值
Out[372]: 
0      Ohio
1      Ohio
2      Ohio
3    Nevada
4    Nevada
Name: state, dtype: object

# 可以通过类似字典的访问方式对 DataFrame 赋值
frame[‘debt’] = 16.5
frame[‘debt’] = np.arange(5.)

# 将列表或数组赋值给某个列时，其长度必须跟DataFrame的长度相匹配。
# 如果赋值的是一个 Series 就会精确匹配 DataFrame 的索引，所有的空位都将被填上缺失值。
val = Series([-1.2,-1.5,-1.7],index = [’two’,’four’,’five’])
frame2[‘debt’] = val
frame2

# 为不存在的列赋值会创建一个新的列，关键字 del 用于删除列
del frame2[‘eastern’]
```

06. 通过索引方式返回的列知识相应数据的视图而已，并不是副本。因此对返回的 Series 所做的任何就地修改都会反映到源 DataFrame 上。通过 Series 的 copy 方法即可显式的复制列。

07. 嵌套字典
* 外层字典的 key 作为列，内层 key 作为行索引。
```py
pop = {'Nevada':{2001:2.4,2002:2.9},
     ...: 'Ohio':{2000:1.5,2001:1.7,2002:3.6}}
frame3 = DataFrame(pop)
frame3
      Nevada  Ohio
2000     NaN   1.5
2001     2.4   1.7
2002     2.9   3.6

frame3.T
        2000  2001  2002
Nevada   NaN   2.4   2.9
Ohio     1.5   1.7   3.6

# 可以指定索引的值 index 指的一定是最内层的字典的 key。
DataFrame(pop,index=[2001,2002,2003])
      Nevada  Ohio
2001     2.4   1.7
2002     2.9   3.6
2003     NaN   NaN

```

08. DataFrame 可以接受多种二维结构的数据，如 二维 ndarray，数组、列表、或元组组成的字典，NumPy的结构化／记录数组等等。
* 如果 DataFrame 各列的数据类型不同，则值数组的数据类型就会选用能兼容所有列的数据类型。

09. 索引对象
* pandas 的索引对象负责管理轴标签喝其他元数据，比如轴名称等。构建 Series 或 DataFrame 时，所用到的任何数组或其他序列的标签都会被转换为一个 Index。
```py
obj = Series(range(3),index = [‘a’,’b’,’c’])
index = obj.index
index
index[1:]
```
* index 对象是不可修改的，immutable 因此用户不能对其进行修改。index 由 pd.Index 类负责管理

```py
index = np.Index(np.arange(3))
obj2 = Series([1.5,-2.5,0],index=index)
obj2.index is index # True
‘a’ in obj2.index # True
```
* 由于开发人员的不懈努力，Index 甚至可以被继承从而实现特别的轴索引功能。
* Index 的方法和属性
```py

# [2017-09-30 利用 python 进行数据分析 pandas]
01. 重新索引
* reindex 方法，作用时创建一个适应新索引的新对象。
```py
obj = Series([4.5,7.2,-5.3,3.6],index=['d','b','a','c'])
obj2 = obj.reindex(['a','b','c','d','e']) # 缺失的值会补充为 NA
obj2 = obj.reindex(['a','b','c','d','e'],fill_value=0) # 指定缺失值的补充值

# method 选项可以做插值处理。
obj3 = Serie([‘blue’,’purple’,’yellow’],index = [0,2,4])
obj3.reindex(range(6),method=‘ffill’) # ffill pad 向前填充或搬运值  bfill backfill 向后填充或搬运值。
# 对于 DataFrame reindex 可以修改行索引，列，或者两个都修改。如果仅传入一个序列，则会重新索引行。
# 使用 columns 关键字即可重新索引列
states = [’Texas’,’Utah’,’California’]
frame.reindex(columns = states)
# 可以同时对行和列进行重新检索，而插值则只能按行应用。
# 利用 ix 的标签索引功能，重新索引任务可以变得更简洁。
frame.ix[[‘a’,’b’,’c’,’d’],states]

# reindex 的参数 index method fill_value limit level copy
```
02. 丢弃指定轴上的项
* 丢弃某条轴上的一个或多个项，只需传入一个索引数组或列表即可，drop 方法会返回删除指定值的新对象，因此 drop 操作不影响源对象
obj = Series(np.arange(5.),index = [‘a’,’b’,’c’,’d’,’e’])
new_obj = obj.drop(‘c’)
obj.drop([‘a’,’d’])

# 对于 DataFrame 可以删除任意轴上的索引值。
```py
data = DataFrame(np.arange(16).reshape((4,4)),index = ['Ohio','Colorado','Utah','New York'],columns = ['one','two','three','four'])
data.drop(['Colorado','Ohio'])
data.drop('two',axis = 1)
```
03. 索引选取和过滤
* Series 索引的工作方式类似于 NumPy 数组的索引，只不过 Series 的索引值 不只是 整数。
```py
obj = Series(np.arange(4.),index = [‘a’,’b’,’c’,’d’])
obj[‘b’]
obj[1]
obj[2:4]
obj[[‘b’,’a’,’d’]]
obj[[1,3]]
obj[obj< 2]

# 利用标签的切片与普通的 Python 切片不同，其末端是包含的。并且不能倒序。
obj[‘b’:’c’]

Out[501]: 
b    1.0
c    2.0

obj[‘c’,’d’] = 5
```
* 对 DataFrame 进行索引其实就是获取一个或多个列。
```py
data = DataFrame(np.arange(16).reshape((4,4)),index = ['Ohio','Colorado','Utah','New York'],columns = ['one','two','three','four'])

data['two']
Out[508]: 
Ohio         1
Colorado     5
Utah         9
New York    13
Name: two, dtype: int64

data[:2]
Out[510]: 
          one  two  three  four
Ohio        0    1      2     3
Colorado    4    5      6     7

data < 5
Out[514]: 
            one    two  three   four
Ohio       True   True   True   True
Colorado   True  False  False  False
Utah      False  False  False  False
New York  False  False  False  False

# DataFrame.ix
data.ix['Colorado',['two','three']]

Out[517]: 
two      5
three    6
Name: Colorado, dtype: int64

data.ix[['Colorado','Utah'],[3,0,1]]

Out[518]: 
          four  one  two
Colorado     7    4    5
Utah        11    8    9

data.ix[data.three > 5,:3]

Out[520]: 
          one  two  three
Colorado    4    5      6
Utah        8    9     10
New York   12   13     14

```
* 作者在设计 pandas 的时候，感觉必须输入 frame[:,col] 才能选取列实在有些啰嗦，而且还很容易出错，因为列的选取是一种最常见的操作，于是把所有的标签索引功能都放到 ix 中了。
```py
# DataFrame 的索引选项
obj[val] 
obj.ix[val]
obj.ix[:,val]
obj.ix[val1,val2]
reindex 方法 xs 方法
icol,irow 方法。
get_value set_value 方法。
```
04. 算术运算和数据对齐
* pandas 最重要的一个功能是，它可以对不同索引的对象进行算术运算，在将对象相加时，如果存在不同的索引对，则结果的索引就是该索引的并集。
```py
s1 = Series([7.3,-2.5,3.4,1.5],index=['a','c','d','e'])
s2 = Series([-2.1,3.6,-1.5,4,3.1],index=['a','c','e','f','g'])
s1 + s2

Out[526]: 
a    5.2
c    1.1
d    NaN
e    0.0
f    NaN
g    NaN
dtype: float64
# 自动的数据对齐操作在不重叠的索引处引入了 NA 值。缺失值会在算术运算过程中传播。
```
* 对于 DataFrame 对齐操作会同时发生在行和列上。
```py
df1 = DataFrame(np.arange(9.).reshape((3,3)),columns=list('bcd'),index=['Ohio','Texas','Colorado'])
df2 = DataFrame(np.arange(12.).reshape((4,3)),columns=list('bde'),index = ['Utah','Ohio','Texas','Oregon'])
df1 + df2

Out[531]: 
            b   c     d   e
Colorado  NaN NaN   NaN NaN
Ohio      3.0 NaN   6.0 NaN
Oregon    NaN NaN   NaN NaN
Texas     9.0 NaN  12.0 NaN
Utah      NaN NaN   NaN NaN
```

# [2017-10-03 利用 python 进行数据分析 pandas]
01. 在算术方法中填充值
* DataFrame 的加法操作会在没有值的地方添加 NA。 有时希望添加一个默认值比如 0.
```py
df1 = DataFrame(np.arange(12.).reshape((3,4)),columns=list('abcd'))
df2 = DataFrame(np.arange(20.).reshape(4,5),columns=list('abcde'))
df1+df2

Out[8]: 
      a     b     c     d   e
0   0.0   2.0   4.0   6.0 NaN
1   9.0  11.0  13.0  15.0 NaN
2  18.0  20.0  22.0  24.0 NaN
3   NaN   NaN   NaN   NaN NaN

df1.add(df2,fill_value=0)
Out[9]: 
      a     b     c     d     e
0   0.0   2.0   4.0   6.0   4.0
1   9.0  11.0  13.0  15.0   9.0
2  18.0  20.0  22.0  24.0  14.0
3  15.0  16.0  17.0  18.0  19.0

# 类似的 在对 Series 和 DataFrame 重新索引时，也可以指定一个填充值。
df1.reindex(columns = df2.columns,fill_value=0)

# 灵活的算术运算
add sub div mul
```

02. DataFrame 和 Seires 之间的运算。
* 跟 NumPy 数组一样，DataFrame 和 Series 之间的算术运算也是有明确规定的。举例说明广播。
```py
arr = np.arange(12.).reshape((3,4))
arr - arr[0]
Out[13]: 
array([[ 0.,  0.,  0.,  0.],
       [ 4.,  4.,  4.,  4.],
       [ 8.,  8.,  8.,  8.]])
# 这就叫做广播。

frame = DataFrame(np.arange(12.).reshape((4,3)),columns=list('bde'),index=['Utah','Ohio','Texas','Oregon'])
Out[15]: 
          b     d     e
Utah    0.0   1.0   2.0
Ohio    3.0   4.0   5.0
Texas   6.0   7.0   8.0
Oregon  9.0  10.0  11.0

series = frame.ix[0]

Out[23]: 
b    0.0
d    1.0
e    2.0
Name: Utah, dtype: float64

frame - series

Out[25]: 
          b    d    e
Utah    0.0  0.0  0.0
Ohio    3.0  3.0  3.0
Texas   6.0  6.0  6.0
Oregon  9.0  9.0  9.0

# 如果某个索引值在 DataFrame 的列或 Series 的索引中找不到，则参运算的两个对象就会被重新索引以形成并集。
series2 = Series(range(3),index=['b','e','f'])
frame + series2

Out[29]: 
          b   d     e   f
Utah    0.0 NaN   3.0 NaN
Ohio    3.0 NaN   6.0 NaN
Texas   6.0 NaN   9.0 NaN
Oregon  9.0 NaN  12.0 NaN

# 如果希望匹配行且在列上广播，则必须使用算术运算方法。
series3 = frame['d']
frame.sub(series3,axis=0)

Out[33]: 
          b    d    e
Utah   -1.0  0.0  1.0
Ohio   -1.0  0.0  1.0
Texas  -1.0  0.0  1.0
Oregon -1.0  0.0  1.0
```
03. 函数应用和映射 
* Numpy 的 ufuncs （元素级数组方法） 也可用于操作 pandas 对象。
```py
frame = DataFrame(np.random.randn(4,3),columns=list(‘bde’),index=[‘Utah’,’Ohio’,’Texas’,’Oregon’])
frame
Out[38]: 
               b         d         e
Utah    0.974643 -1.008085 -1.941395
Ohio    0.957493  0.258852 -0.066635
Texas  -0.547485 -0.135344  0.471215
Oregon  0.281371  0.526842 -0.492711

np.abs(frame)
Out[39]: 
               b         d         e
Utah    0.974643  1.008085  1.941395
Ohio    0.957493  0.258852  0.066635
Texas   0.547485  0.135344  0.471215
Oregon  0.281371  0.526842  0.492711
```
* 另一个常见的操作是将函数应用到各列或行所形成的一维数组上。
```py
f = lambda x:x.max() - x.min()
frame.apply(f)

Out[42]: 
b    1.522127
d    1.534926
e    2.412611
dtype: float64

frame.apply(f,axis=1)

Out[43]: 
Utah      2.916038
Ohio      1.024128
Texas     1.018700
Oregon    1.019552
dtype: float64
```
* 许多最为常见的数组统计功能都被实现为 DataFrame 的方法，（如 sum 和 mean）因此无需使用 apply 方法。
```py
In [44]: def f(x):
    ...:     return Series([x.min(),x.max()],index=['min','max'])
    ...: 
frame.apply(f)
Out[47]: 
            b         d         e
min -0.547485 -1.008085 -1.941395
max  0.974643  0.526842  0.471215
```
* 此外，元素级的 Python 函数也是可以用的。假如想得到 frame 中各个浮点值的格式化字符串，使用 applymap 即可。
```py
format = lambda x: '%.2f' % x
frame.applymap(format)

Out[49]: 
            b      d      e
Utah     0.97  -1.01  -1.94
Ohio     0.96   0.26  -0.07
Texas   -0.55  -0.14   0.47
Oregon   0.28   0.53  -0.49

# 之所以叫 applymap 是因为 Series 有一个用于应用元素级函数的 map 方法。
frame[‘e’].map(foramt)
Out[52]: 
Utah      -1.94
Ohio      -0.07
Texas      0.47
Oregon    -0.49
Name: e, dtype: object
```
04. 排序和排名。
* 要对行或列索引进行排序，可使用 sort_index 方法，返回一个已排序的新对象。
```py
obj = Series(range(4),index=[‘d’,’a’,’b’,’c’])
obj.sort_index()

Out[55]: 
a    1
b    2
c    3
d    0
dtype: int64

obj.sort_index().sort_values()
Out[61]: 
d    0
a    1
b    2
c    3
dtype: int64
```
* 对于 DataFrame 可以根据任意一个轴上的索引进行排序。
```py
frame = DataFrame(np.arange(8).reshape((2,4)),index=[‘three’,’one’],columns=[‘d’,’a’,’b’,’c’])
frame.sort_index()

Out[65]: 
       d  a  b  c
one    4  5  6  7
three  0  1  2  3

frame.sort_index(axis=1)
Out[67]: 
       a  b  c  d
three  1  2  3  0
one    5  6  7  4

# 使用 ascending 参数设置升序还是降序
frame.sort_index(axis=1,ascending=False)

obj = Series([4,7,-3,2])
obj.sort_index()

obj.sort_values()
Out[76]: 
2   -3
3    2
0    4
1    7
dtype: int64
# 在排序时，任何缺失值默认都会被放到 Series 的末尾。
obj = Series([4,np.nan,7,np.nan,-3,2])

Out[80]: 
4   -3.0
5    2.0
0    4.0
2    7.0
1    NaN
3    NaN
dtype: float64
```
* 在 DataFrame 上，希望根据一个或多个列中的值进行排序，将一个或多个列的名字传递给 by 选项即可达到该目的。
```py
frame = DataFrame({'b':[4,7,-3,2],'a':[0,1,0,1]})
frame.sort_values(by='b')
Out[84]: 
   a  b
2  0 -3
3  1  2
0  0  4
1  1  7

frame.sort_values(by=['a','b'])
Out[85]: 
   a  b
2  0 -3
0  0  4
3  1  2
1  1  7
```
* rank 跟排序密切相关，会增设一个排名值，从 1 开始。默认情况下，rank 时通过 为各组分配一个平均排名 的方式破坏平级关系的。
```py
obj = Series([7,-5,7,4,2,0,4])
obj.rank()
Out[88]: 
0    6.5
1    1.0
2    6.5
3    4.5
4    3.0
5    2.0
6    4.5
dtype: float64

obj.rank(method='first')
Out[89]: 
0    6.0
1    1.0
2    7.0
3    4.0
4    3.0
5    2.0
6    5.0
dtype: float64
# method 排名时用于破坏平级关系
’average‘ 默认 ‘min’ ‘max’ ‘first’
```
# [2017-10-04 利用 python 进行数据分析 pandas]
01. 带有重复值的轴索引
```py
obj = Series(range(5),index = ['a','a','b','b','c'])
Index 的 is_unique 属性返回索引值是否唯一。
obj.index.is_unique # False

# 对于带有重复值的索引，数据选取的行为会有些不同，如果某个索引对应多个值，则返回一个 Series，对应单个值，返回一个标量。
obj = Series(range(5),index = ['a','a','b','b','c'])
obj['a']
Out[102]: 
a    0
a    1
dtype: int64

# 对于 DataFrame 的行进行索引时也是如此。
df = DataFrame(np.random.randn(4,3),index = ['a','a','b','b'])
df.ix['a']
Out[107]: 
          0         1         2
a  0.358932  0.266385  2.059227
a  0.408200  1.366962  2.129144
```
02. 汇总和计算统计描述。pandas 对象拥有一组常用的数学和统计方法。它们大部分都属于约简和汇总统计，用于从 Series 中提取单个值，或从 DataFrame 的行或列中提取一个 Series。
```py
df = DataFrame([[1.4,np.nan],[7.1,-4.5],[np.nan,np.nan],[0.75,-1.3]],index=['a','b','c','d'],columns=['one','two'])
df
Out[111]: 
    one  two
a  1.40  NaN
b  7.10 -4.5
c   NaN  NaN
d  0.75 -1.3
# NA 值会自动排除
df.sum()
Out[112]: 
one    9.25
two   -5.80
dtype: float64

# axis=1 为按照列统计
df.sum(axis=1)
Out[113]: 
a    1.40
b    2.60
c    0.00
d   -0.55
dtype: float64
# skipna 参数设置是否忽略 NA
df.mean(axis=1,skipna=False)
Out[114]: 
a      NaN
b    1.300
c      NaN
d   -0.275
dtype: float64

# 约简方法选项 
axis skipna level
# 有些方法返回的是间接统计，比如达到最小值或最大值的索引。
df.idxmax()
Out[115]: 
one    b
two    d
dtype: object

# 累计求值
df.cumsum()
Out[116]: 
    one  two
a  1.40  NaN
b  8.50 -4.5
c   NaN  NaN
d  9.25 -5.8

# describe() 用于一次性产生多个汇总统计
df.describe()
Out[121]: 
            one       two
count  3.000000  2.000000
mean   3.083333 -2.900000
std    3.493685  2.262742
min    0.750000 -4.500000
25%    1.075000 -3.700000
50%    1.400000 -2.900000
75%    4.250000 -2.100000
max    7.100000 -1.300000

# 对于非数值型数据，describe 会产生另外一种汇总统计
obj = Series(['a','a','b','c'] * 4)
obj.describe()
Out[124]: 
count     16
unique     3
top        a
freq       8
dtype: object

# 其他汇总统计方法
count # 非 NA 的数量
describe
min max
argmin argmax	# 最大最小值的索引位置 整数
idxmin idxmax	# 最大最小值的索引
quantile	# 计算样本的分位数 （0到1）
sum
mean
median	# 值的算术中位数
mad	# 根据平均值计算平均绝对离差
var
std
skew	# 样本值的偏度 （三阶距）
kurt	# 样本值的峰度 （四阶距）
cumsum	# 样本值的累计和
cummin cummax	# 样本值的累计最大值和累计最小值
cumprod	# 样本值的累计积
diff	# 计算一阶差分 （对时间序列很有哟哦那个）
pct_change	# 计算百分数变化
```
03. 相关系数与协方差
```py
tail
coor
cov
corrwith
```
04. 唯一值、值计数以及成员资格
* 第一个函数是 unique()，它可以得到 Series 中唯一值数组
```py
obj = Series(['c','a','d','a','a','b','b','c','c'])
uniques = obj.unique()
array(['c', 'a', 'd', 'b'], dtype=object)
需要排序可调用 sort()
uniques.sort()
unique
array(['a', 'b', 'c', 'd'], dtype=object)
```
* value_counts 计算 Series 中各值出现的频率
```py
obj.value_counts()
Out[24]: 
c    3
a    3
b    2
d    1
dtype: int64

# value_counts() 还是一个顶级 pandas 方法，可用于任何数组或序列
pd.value_counts(obj.values,sort=False)
Out[26]: 
a    3
b    2
c    3
d    1
dtype: int64
```
* isin 用于判断矢量化集合的成员资格，可用于选取 Series 中或 DataFrame 列中数据的子集
```py
mask = obj.isin[‘b’,’c’]
mask
Out[28]: 
0     True
1    False
2    False
3    False
4    False
5     True
6     True
7     True
8     True
dtype: bool

obj[mask]
Out[29]: 
0    c
5    b
6    b
7    c
8    c
dtype: object
# DataFrame 的 value_counts
data = DataFrame({'Qu1':[1,3,4,3,4],
    ...: 'Qu2':[2,3,1,3,2],
    ...: 'Qu3':[1,5,2,4,4]})

result = data.apply(pd.value_counts).fillna(0)
result
Out[33]: 
   Qu1  Qu2  Qu3
1  1.0  1.0  1.0
2  0.0  2.0  1.0
3  2.0  2.0  0.0
4  2.0  0.0  2.0
5  0.0  0.0  1.0
```
05. 处理缺失数据。
* 数据缺失在大部分数据分析应用中都很常见，pandas 的设计目标之一就是让缺失数据的处理任务尽量轻松 ⭐️⭐️⭐️⭐️⭐️。例如pandas 对象上的所有描述统计都派出了缺失数据。
* pandas 使用浮点值 NAN（Not a Number）表示浮点和非浮点数组中的缺失数据。它只是一个便于检测出来的标记而已。
```py
string_data = Series(['aardvark','artichoke',np.nan,'avocado'])
string_data.isnull()
Out[40]: 
0    False
1    False
2     True
3    False
dtype: bool

# Python 内置的 None 值也会被当作 NA 处理。
string_data[0] = None
string_data.isnull()
Out[42]: 
0     True
1    False
2     True
3    False
dtype: bool
```
* NA 处理方法
dropna fillna isnull notnull

06. 滤除缺失数据
* 对于一个 Series dropna 返回一个仅含非空数据和索引值的 Series。不会修改源数据。
```py
from numpy import nan as NA
data = Series([1,NA,3.5,NA,7])

data.dropna()
Out[46]: 
0    1.0
2    3.5
4    7.0
dtype: float64

data
Out[47]: 
0    1.0
1    NaN
2    3.5
3    NaN
4    7.0
dtype: float64

# 也可以通过布尔型索引达到这个目的
data[data.notnull()]
Out[49]: 
0    1.0
2    3.5
4    7.0
dtype: float64
```
* 而对于 DataFrame 对象，事情就有点复杂了，可能希望丢弃全 NA 或含 NA 的行或列。dropna 默认丢弃任何含有缺失值的行。
```py
data = DataFrame([[1.,6.5,3.],[1.,NA,NA],[NA,NA,NA],[NA,6.5,3.]])
data
Out[56]: 
     0    1    2
0  1.0  6.5  3.0
1  1.0  NaN  NaN
2  NaN  NaN  NaN
3  NaN  6.5  3.0

cleaned
Out[57]: 
     0    1    2
0  1.0  6.5  3.0

# 传入 how=‘all’ 将只丢弃全为 NA 的那些行。要按照这种方式丢弃列，只需传入 axis=1 即可
# 另一个滤除 DataFrame 行的问题涉及时间序列数据，假设只想留下一部分观测数据，可以用 thresh 参数实现此目的
df = DataFrame(np.random.randn(7,3))
df.ix[:4,1] = NA;df.ix[:2,2] = NA
df
Out[65]: 
          0         1         2
0 -1.275628       NaN       NaN
1  0.832002       NaN       NaN
2 -1.766536       NaN       NaN
3 -0.267438       NaN -1.197388
4  0.546133       NaN -0.239568
5 -1.204937 -1.655411  0.003078
6 -0.156225 -0.090273 -0.465353

df.dropna(thresh=3)
Out[67]: 
          0         1         2
5 -1.204937 -1.655411  0.003078
6 -0.156225 -0.090273 -0.465353

In [68]: df.dropna(thresh=2)
Out[68]: 
          0         1         2
3 -0.267438       NaN -1.197388
4  0.546133       NaN -0.239568
5 -1.204937 -1.655411  0.003078
6 -0.156225 -0.090273 -0.465353
```
07. 填充缺失数据 fillna()
```py
df.fillna(0) # 将 NA 填充为 0
In [73]: df.fillna({1:0.5,2:-1}) # 传入一个字典，可以实现对不同的列填充不同的值。

# fillna 默认会返回新对象，但也可以对现有对象进行就地修改
_ = df.fillna(0,inplace=True)

# 对 reindex 有效的那些插值方法也可用于fillna
df = DataFrame(np.random.randn(6,3))
df.ix[2:1] = NA;df.ix[4:2] = NA
df
Out[84]: 
          0         1         2
0 -1.845277  0.238193  0.581655
1 -0.973534 -1.457389 -0.282177
2 -0.743969       NaN  0.430684
3 -1.058048       NaN  2.045487
4  1.082118       NaN       NaN
5 -0.632979       NaN       NaN

df.fillna(method='ffill')
Out[85]: 
          0         1         2
0 -1.845277  0.238193  0.581655
1 -0.973534 -1.457389 -0.282177
2 -0.743969 -1.457389  0.430684
3 -1.058048 -1.457389  2.045487
4  1.082118 -1.457389  2.045487
5 -0.632979 -1.457389  2.045487

# 作用于返回值，不会修改源数据。
df.fillna(method=‘ffill’,limit=2)
```
* 可以利用 fillna 实现很多别的功能，例如传入 Series 的平均值或中位数
```py
data = Series([1.,NA,3.5,NA,7])
data.fillna(data.mean())
Out[89]: 
0    1.000000
1    3.833333
2    3.500000
3    3.833333
4    7.000000
dtype: float64

# fillna 的参数
value
method
axis
inplace
limit
```
08. 层次化索引 能在一个轴上拥有多个索引级别。
```py
data = Series(np.random.randn(10),index=[['a','a','a','b','b','b','c','c','d','d'],[1,2,3,1,2,3,1,2,2,3]])
data
Out[92]: 
a  1   -0.305510
   2    0.094667
   3   -0.388802
b  1   -2.000582
   2    1.440727
   3    0.752909
c  1    1.752914
   2   -0.355938
d  2    0.130376
   3   -0.791289
dtype: float64

data.index
Out[93]: 
MultiIndex(levels=[['a', 'b', 'c', 'd'], [1, 2, 3]],
           labels=[[0, 0, 0, 1, 1, 1, 2, 2, 3, 3], [0, 1, 2, 0, 1, 2, 0, 1, 1, 2]])

# 层次化索引对象选取子集的操作
data[‘b’]
data[‘b’:’c’]
data/ix[[‘b’,’d’]]
# 内层选取
data[:,2]
```
* 层次化索引在数据重塑和基于分组的操作中扮演着重要的角色。
```py
data.unsatck()
Out[99]: 
          1         2         3
a -0.305510  0.094667 -0.388802
b -2.000582  1.440727  0.752909
c  1.752914 -0.355938       NaN
d       NaN  0.130376 -0.791289

# data.unstack() 与 data.stack() 互为逆操作。
# 对于 DataFrame 每条轴都可以有分层索引。
frame = DataFrame(np.arange(12).reshape((4,3)),index=[['a','a','b','b'],[1,2,1,2]],columns=[['Ohio','Ohio','Colorado'],['Green','Red','Green']])

In [103]: frame
Out[103]: 
     Ohio     Colorado
    Green Red    Green
a 1     0   1        2
  2     3   4        5
b 1     6   7        8
  2     9  10       11

# 可以指定各层的名称
In [104]: frame.index.names=['key1','key2']

In [105]: frame.columns.names=['state','color']

In [106]: frame
Out[106]: 
state      Ohio     Colorado
color     Green Red    Green
key1 key2                   
a    1        0   1        2
     2        3   4        5
b    1        6   7        8
     2        9  10       11

# 可以单独定义 MultiIndex 复用
In [110]: from pandas import MultiIndex

In [111]: index = MultiIndex.from_arrays([['Ohio','Ohio','Colorado'],['Green','Red','Green']],names=['state','color'])

In [112]: index
Out[112]: 
MultiIndex(levels=[['Colorado', 'Ohio'], ['Green', 'Red']],
           labels=[[1, 1, 0], [0, 1, 0]],
           names=['state', 'color'])

# 重新分级顺序。有时需要重新调整某条轴上各级别的顺序，或根据指定级别上的值对数据进行排序。
# swaplevel 接收两个级别编号或名称，并返回一个互换了级别的新对象，数据不会发生变化。
frame.swaplevel(‘key1’,’key2’)
# sortlevel 根据耽搁级别中的值对数据进行排序。 交换级别时，常常也会用到 sortlevel 这样最终结果就是有序的了。
```
* 根据级别汇总统计 DataFrame 和 Series 的描述和汇总统计的 level 选项用于指定在某条轴上求和的级别。
```py
frame.sum(level='key2')
Out[117]: 
state  Ohio     Colorado
color Green Red    Green
key2                    
1         6   8       10
2        12  14       16

frame.sum(level='color',axis=1)
Out[119]: 
color      Green  Red
key1 key2            
a    1         2    1
     2         8    4
b    1        14    7
     2        20   10
```
* 人们经常想要将 DataFrame 的一个或多个列当作行索引来用，或者可能希望将行索引变成 DataFrame 的列。
```py
frame = DataFrame({'a':range(7),'b':range(7,0,-1),'c':['one','one','one','two','two','two','two'],'d':[0,1,2,0,1,2,3,]})

In [122]: frame
Out[122]: 
   a  b    c  d
0  0  7  one  0
1  1  6  one  1
2  2  5  one  2
3  3  4  two  0
4  4  3  two  1
5  5  2  two  2
6  6  1  two  3

In [123]: frame2 = frame.set_index(['c','d'])

In [124]: frame2
Out[124]: 
       a  b
c   d      
one 0  0  7
    1  1  6
    2  2  5
two 0  3  4
    1  4  3
    2  5  2
    3  6  1

# 默认情况下，那些列会从 DataFrame 中移除，但也可以将其保留下来。
In [125]: frame.set_index(['c','d'],drop=False)
Out[125]: 
       a  b    c  d
c   d              
one 0  0  7  one  0
    1  1  6  one  1
    2  2  5  one  2
two 0  3  4  two  0
    1  4  3  two  1
    2  5  2  two  2
    3  6  1  two  3

# reset_index 的功能跟 set_index 刚好相反，层次化索引的级别会被转移到列里面。
frame2.reset_index()
Out[128]: 
     c  d  a  b
0  one  0  0  7
1  one  1  1  6
2  one  2  2  5
3  two  0  3  4
4  two  1  4  3
5  two  2  5  2
6  two  3  6  1
```
# [2017-10-05 利用 python 进行数据分析 pandas]
01. 其他关于 pandas 的话题 证书索引
* 由整数索引的 pandas 对象与 Python 数据结构在索引语义上有些不同。
```py
ser = Series(np.arange(3.))
ser[-1] # error!!
# 而
ser2 = Series(np.arange(3.),index=[‘a’,’b’,’c’])
ser2[-2]
Out[135]: 2.0
# 是因为  
ser
Out[130]: 
0    0.0
1    1.0
2    2.0
dtype: float64

ser2
Out[134]: 
a    0.0
b    1.0
c    2.0
dtype: float64

# 为保持良好的一致性，如果轴索引含有索引器，那么根据整数进行数据选取的操作将总是面向标签的
```
* 如果需要可靠的，不考虑索引类型的，基于位置的索引，可以使用 Series 的iget_value 方法 和 DataFrame 的 irow 和 icol 方法。

02. 面板数据 pandas 有一个 Panel 数据结构，可以看作一个三维版的 DataFrame。
* pandas 的大部分开发工作都集中在表格型数据的操作上，因为这些数据更常见，而且层次化索引也是的多数情况下没有必要使用真正的 N 维数组。
* 可以用一个由 DataFrame 对象组成的字典或一个三维 ndarray 来创建 Panel 对象。

03. 数据加载 存储和文件格式。
* NumPy 提供了一个低级但异常高效的二进制数据加载和存储机制，包括对内存映射数组的支持等。
* 输入输出通常可以划分为几个大类，读取文本文件和其他更高效的磁盘存储格式，加载数据库中的数据，利用 WebAPI操作网络资源。
04. 读写文本格式的数据。
* pandas 提供了一些用于将表格型数据读取为 DataFrame 对象的函数，其中 read_csv 和 read_table 最为常用。
```py
read_csv	# 从文件 URL、文件型对象中加载带分隔符的数据，默认分隔符为逗号。
read_table	# 从文件 URL、文件型对象中加载带分隔符的数据。默认分隔符为制表符 （’\t’）
read_fwf	# 读取定宽列格式数据 （也就是说，没有分隔符）
read_clipboard	# 读取剪切板中的数据，可以看作 read_table 的剪贴板版，在将网页转换为表格时很有用。
```
* 可以用到的函数选项
```py
索引
类型推断和数据转换
日期解析
迭代	# 对大文件进行逐块迭代
不规整数据问题
```
* 举个例子
```py
df = pd.read_csv('ch06/ex1.csv')

In [146]: df
Out[146]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo

# 也可以使用 read_table 但是要指定分隔符。
pd.read_table('ch06/ex1.csv',sep=',')
Out[147]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
```
* 并不是所有的文件都有标题行，对于没有标题行的，可以使用 pandas 为其分配默认的列名，也可以自己定义列名。
```py
!cat ch06/ex2.csv
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo
In [149]: pd.read_csv('ch06/ex2.csv',header=None)
Out[149]: 
   0   1   2   3      4
0  1   2   3   4  hello
1  5   6   7   8  world
2  9  10  11  12    foo

# 指定列名
pd.read_csv('ch06/ex2.csv',names=['a','b','c','d','message'])
Out[150]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo

# 假设希望某一列最为 DataFrame 的索引，可以通过 index_col 指定。
names = ['a','b','c','d','message']
pd.read_csv('ch06/ex2.csv',names=names,index_col='message')
Out[153]: 
         a   b   c   d
message               
hello    1   2   3   4
world    5   6   7   8
foo      9  10  11  12
```
* 如果希望将多个列做成一个层次化索引，只需传入由列编号或列名组成的列表即可。
```py
!cat ch06/csv_mindex.csv
key1,key2,value1,value2
one,a,1,2
one,b,3,4
one,c,5,6
one,d,7,8
two,a,9,10
two,b,11,12
two,c,13,14
two,d,15,16

parsed = pd.read_csv('ch06/csv_mindex.csv',index_col=['key1','key2'])
Out[156]: 
           value1  value2
key1 key2                
one  a          1       2
     b          3       4
     c          5       6
     d          7       8
two  a          9      10
     b         11      12
     c         13      14
     d         15      16
```
* 有些表格可能不是用固定的分隔符去分隔字段的，（比如空白符或其他模式），对于这种情况，可以编写一个正则表达式来作为 read_table 的分隔符。
```py
list(open('ch06/ex3.txt'))
Out[157]: 
['            A         B         C\n',
 'aaa -0.264438 -1.026059 -0.619500\n',
 'bbb  0.927272  0.302904 -0.032399\n',
 'ccc -0.264273 -0.386314 -0.217601\n',
 'ddd -0.871858 -0.348382  1.100491\n']

result = pd.read_table('ch06/ex3.txt',sep='\s+')
In [159]: result
Out[159]: 
            A         B         C
aaa -0.264438 -1.026059 -0.619500
bbb  0.927272  0.302904 -0.032399
ccc -0.264273 -0.386314 -0.217601
ddd -0.871858 -0.348382  1.100491
# 这里由于列名比数据行少1 所以 read_table 推断第一列应该是 DataFrame 的索引
```
* 解析器函数还有许多参数可以帮助处理各种各样的异形文件格式，比如，用 skiprows 跳过文件的第一行、第三行、和第四行。
```py
!cat ch06/ex4.csv
# hey!
a,b,c,d,message
# just wanted to make things more difficult for you
# who reads CSV files with computers, anyway?
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo

pd.read_csv('ch06/ex4.csv',skiprows=[0,2,3])
Out[165]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
```
* 缺失值处理是文件解析任务中的一个重要组成部分，缺失数据经常是要么没有，要么用某个标记值表示。默认情况下，pandas 会用一组经常出现的标记值进行识别，如 NA，-1.#IND 以及 NULL 等。
```py
!cat ch06/ex5.csv
something,a,b,c,d,message
one,1,2,3,4,NA
two,5,6,,8,world
three,9,10,11,12,foo

result = pd.read_csv('ch06/ex5.csv')

In [168]: result
Out[168]: 
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       two  5   6   NaN   8   world
2     three  9  10  11.0  12     foo

pd.isnull(result)
Out[171]: 
   something      a      b      c      d  message
0      False  False  False  False  False     True
1      False  False  False   True  False    False
2      False  False  False  False  False    False
# na_values 可以接受一组用于表示缺失值的字符串
result = pd.read_csv(‘ch06/ex5.csv’,na_values=[‘NULL’])

# 可以用一个字典为各列指定不同的 NA 标记值
sentinels = {'message':['foo','NA'],'something':['two']}
pd.read_csv('ch06/ex5.csv',na_values=sentinels)
Out[173]: 
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       NaN  5   6   NaN   8   world
2     three  9  10  11.0  12     NaN
```
* read_csv/read_talbe函数的参数
```py
path
sep 或 delimiter
header
index_col
names
skiprows
na_values
comment
parse_dates
keep_date_col
converters
dayfirst
date_parser
nrows
iterator
chunksize
skip_footer
verbose
encoding
squeeze
thousands
```
05. 逐块读取文本文件
* nrows 指定读取的行数
```py
result = pd.read_csv('ch06/ex6.csv',nrows=5)
result
Out[177]: 
        one       two     three      four key
0  0.467976 -0.038649 -0.295344 -1.824726   L
1 -0.358893  1.404453  0.704965 -0.200638   B
2 -0.501840  0.659254 -0.421691 -0.057688   G
3  0.204886  1.074134  1.388361 -0.982404   R
4  0.354628 -0.133116  0.283763 -0.837063   Q
```
* 逐块读取文件，需要设置 chunksize（行数）
chunker = pd.read_csv('ch06/ex6.csv',chunksize=1000)

In [179]: chunker
Out[179]: <pandas.io.parsers.TextFileReader at 0x114a56080>
# 返回的这个 TextFileReader 对象可以根据 chunksize 对文件进行逐块迭代。
tot = Series([])
for piece in tot:
	tot = tot.add(piece[‘key’].value_counts(),fill_value=0)
tot = tot.sort_values(ascending=False)
```
06. 将数据写出到文本格式。
* 利用 DataFrame 的 to_csv 方法，可以将数据写到一个以逗号分隔的文件中。
```py
data = pd.read_csv('ch06/ex5.csv')

In [190]: data
Out[190]: 
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       two  5   6   NaN   8   world
2     three  9  10  11.0  12     foo

In [191]: data.to_csv('ch06/kewei.csv')

In [192]: !cat ch06/kewei.csv
,something,a,b,c,d,message
0,one,1,2,3.0,4,
1,two,5,6,,8,world
2,three,9,10,11.0,12,foo
```
# 可用 sep 参数指定分隔符，na_rep 参数指定缺失值。
# 如果没有设置其他选项，则会写出行和列的标签，可用 index=False header=False 禁用。

# 读取为 Series 无 header 行，第一列做索引。还可以使用 from_csv
Series.from_csv(‘ch06/weiwei.csv’,parse_date=True)
```
06. 手工处理分隔符格式。
* 大部分情况可以用 pandas.read_table 加载文件数据，但是对于畸形的文件，需要做一些处理。
```py
!cat ch06/ex7.csv
"a","b","c"
"1","2","3"
"1","2","3","4"
# 对于任何单字符分隔符文件，可以直接使用 Python 内置的 csv 模块，将任意已打开的文件或文件型的对象传给 csv.reader。

lines
Out[33]: [['a', 'b', 'c'], ['1', '2', '3'], ['1', '2', '3', '4']]

In [34]: header,values = lines[0],lines[1:]

In [35]: header
Out[35]: ['a', 'b', 'c']

In [36]: values
Out[36]: [['1', '2', '3'], ['1', '2', '3', '4']]

In [37]: data_dict = {h:v for h,v in zip(header,zip(*values))}

In [38]: data_dict
Out[38]: {'a': ('1', '1'), 'b': ('2', '2'), 'c': ('3', '3')}
```
* csv 文件的形式有很多，只需定义 csv.Dialect 的一个子类即可定义出新格式，（如专门的分隔符，字符串引用约定，行结束符等）

# [2017-10-09 利用 python 进行数据分析 数据加载、存储与文件格式]
01. JSON 是一种比表格型文本格式灵活的多多数据格式，已经成为通过 http 请求在 Web 浏览器和其他应用程序之间发送数据的标准格式之一。
```py import json
obj = '''
    ...: {"name":"Wes","places_lived":["United States","Spain","Germany"],"pet":null,"siblings":[{"name":"Scott","age":25,"pet":"ZZuko"},{"name":"Katie","age":33,"pet":"Cisco"}]}
    ...: '''
# json.loads 将 JSON 字符串转换为 Python 形式。json.dumps 将 Python 对象转换为 JSON 格式
result = json.loads(obj)
asjson = json.dumps(result)

# 根据 json 对象选取字段构造 DataFrame
siblings = DataFrame(result['siblings'],columns=['name','age'])

In [112]: siblings
Out[112]: 
    name  age
0  Scott   25
1  Katie   33
```
02. XML 和 HTML：Web 信息收集
* Python 有很多可以读写 HTML 和 XML 格式数据的库，lxml就是其中之一。
```py
from lxml.html import parse
from urllib import request

# 请求 url 过滤数据 解析数据 等等。
parsed = parse(request.urlopen('http://finance.yahoo.com/q/op?s=AAPL+Options'))
parsed
Out[5]: <lxml.etree._ElementTree at 0x108457c48>

doc = parsed.getroot()

In [7]: doc
Out[7]: <Element html at 0x108462b38>

links = doc.findall('.//a')

# XML 数据很复杂，每个标记都可以有元数据
from io import StringIO
tag = '<a href="http://www.google.com">Google</a>'
root = objectify.parse(StringIO(tag)).getroot()
In [13]: root.get('href')
Out[13]: 'http://www.google.com'

In [14]: root.text
Out[14]: 'Google'
```

# [2017-10-10 利用 python 进行数据分析 数据加载、存储与文件格式]
01. 二进制数据格式
* 实现数据的二进制格式存储最简单的办法之一是使用 Python 内置的 pickle 序列化，为了使用方便，pandas 对象都有一个用于将数据以 pickle 形式保存到磁盘上的 to_pickle 方法。
```py
frame = pd.read_csv(‘ch06/ex1.csv’)
frame.to_pickle(‘ch06/frame_pickle’)
pd.read_pickle(‘ch06/frame_pickle’)

# 原始 csv 文件的大小为58字节 硬盘上的4K pickle 文件的大小为923字节 硬盘上的4K
In [24]: % timeit frame = pd.read_csv('ch06/ex1.csv')
1000 loops, best of 3: 899 µs per loop

In [25]: % timeit pd.read_pickle('ch06/frame_pickle')
1000 loops, best of 3: 288 µs per loop
# 可以看到加载速度变快了
```
02. 使用 HDF5 格式
* 很多工具都能实现高效读写磁盘上以二进制格式存储的科学数据，HDF5 是其中一个流行的工业级库。HDF 是指 (hierarchical data format)层次型结构数据。
* 每个 HDF5 文件都含有一个文件系统式节点结构，它使你能够存储多个数据集并支持源数据。与其他简单格式相比，HDF5 支持多种压缩器的即时压缩，还能更高效的存储重复模式数据。对于那些非常大的无法直接放入内存的数据集，HDF5 就是不错的选择，因为它可以高效地分块读写。
* Python 中的 HDF5 库有两个接口，即PyTables 和 h5py，他们各自采取了不同的问题解决方式，h5py 提供了一种直接而高级的 HDF5 API 访问接口，而 PyTables 则抽象了 HDF5 的徐国细节，以提供多种灵活的数据容器，表索引，查询功能，以及对核外计算技术（out-of-core computation）的某些支持
```py
store = pd.HDFStore(‘mydata.h5’)
store[‘obj1’] = frame
dic1 = {}
dic1[‘obj1’] = frame

In [42]: %timeit obj1 = store['obj1']
100 loops, best of 3: 2.07 ms per loop

In [43]: %timeit obj1 = dic1['obj1']
10000000 loops, best of 3: 44.1 ns per loop
# 可以看到 从字典获取对象与从 HDF5 中获取对象所需的时间。
```
* 如果需要处理海量数据，还是要好好研究一下PyTables 和 h5py，看看他们能满足那些需求，由于许多数据分析问题都是 IO 密集型，而不是 CPU 密集型，利用 HDF5 这样的工具能够显著提升应用程序的效率。
* HDF5 不是数据库，它最适合用作 “一次写多次读”的数据集，虽然数据可以在任何时候被添加到文件中，但如果同时发生多个写操作，文件就可能会被破坏。
03. 读取 Microsoft Excel 文件
* pandas 的 ExcelFile 类支持读取存储在 Excel 2003 种的表格型数据，通过传入一个xls或xlsx文件的路径即可创建一个ExcelFile实例。
```py
In [45]: xls_file = pd.ExcelFile('/Users/zhuchao/pydata-book/ch06/ex1.xlsx')

In [46]: table = xls_file.parse('Sheet1')

In [47]: table
Out[47]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
```
04. 使用 HTML 和 Web API
* 许多网站都有一些通过 JSON 或其他格式提供数据的公共 API，可以通过 requests包访问这些 API。
```py
url_iplocate = ‘http://int.dpool.sina.com.cn/iplookup/iplookup.php?format=json&ip=218.4.255.255’
url_map = ‘http://gc.ditu.aliyun.com/regeocoding?l=39.938133,116.395739&type=001’

resp = requests.get(url_iplocate)
data = json.loads(resp.text)
data.keys()
```
05. 使用数据库
```py
import sqlite3
query = "create table test (a varchar(20),b varchar(20),c real,d integer);"
con = sqlite3.connect(':memory:')
con.commit()
data = [('Atlanta','Georgia',1.25,6),('Tallshassee','Florida',2.6,3),('Sacramento','California',1.7,5)]
stmt = "insert into test values(?,?,?,?)"
con.commit()
cursor = con.execute('select * from test')
rows = cursor.fetchall()

In [119]: rows
Out[119]: 
[('Atlanta', 'Georgia', 1.25, 6),
 ('Tallshassee', 'Florida', 2.6, 3),
 ('Sacramento', 'California', 1.7, 5)]

In [124]: cursor.description
Out[124]: 
(('a', None, None, None, None, None, None),
 ('b', None, None, None, None, None, None),
 ('c', None, None, None, None, None, None),
 ('d', None, None, None, None, None, None))

# pandas 提供了一个简化的 read_sql 函数，只需传入 select 语句和连接对象即可。

In [138]: import pandas.io.sql as sql
In [140]: sql.read_sql('select * from test',con)
Out[140]: 
             a           b     c  d
0      Atlanta     Georgia  1.25  6
1  Tallshassee     Florida  2.60  3
2   Sacramento  California  1.70  5

```
06. 数据规整化：清理、转换、合并、重塑
* 数据分析和建模方面的大量变成工作都在数据准备上，pandas 和 Python 提供了一组高级的、灵活的、高效的核心函数和算法。
```py
# pandas 内置的合并方法
pandas.merge()	# 数据合并
pandas.concat	# 沿着一条轴将多个对象堆叠到一起
combine_first	# 将重复数据编接在一起
07. 数据库风格的 DataFrame 合并
```py
In [141]: df1 =DataFrame({'key':['b','b','a','c','a','a','b'],'data1':range(7)})

In [142]: df2 = DataFrame({'key':['a','b','d'],'data2':range(3)})

In [143]: df1
Out[143]: 
   data1 key
0      0   b
1      1   b
2      2   a
3      3   c
4      4   a
5      5   a
6      6   b

In [144]: df2
Out[144]: 
   data2 key
0      0   a
1      1   b
2      2   d

In [145]: result = pd.merge(df1,df2)

In [146]: result
Out[146]: 
   data1 key  data2
0      0   b      1
1      1   b      1
2      6   b      1
3      2   a      0
4      4   a      0
5      5   a      0
```
* 如果没有指定要用哪个列进行连接，merge 就会将重叠的列名当作键，不过最好显示指定一下。
```py
pd.merge(df1,df2,on=‘key’)
# 列名不同可以分别指定。
# 多对多连接产生的结果是行的笛卡尔积
# 要根据多哥键进行合并，传入一个由列名组成的列表即可
pd.merge(left,right,on=['key1','key2'],how='outer')

# 重复列名的处理，merge 有一个实用的 suffixes 选项，用于指定附加到左右两个 DataFrame 对象的重叠列名上的字符串。

# merge 函数的参数
left
right
how
on
left_on
right_on
left_index
right_index
sort	# 根据连接键对合并后的数据进行排序，默认为 True。有时在处理大数据集时，禁用该选项可获得更好的性能。
suffixes
copy	# 默认设置为 False，可以在某些特殊情况下避免将数据复制到结果数据结构中，默认总是复制。
```
08. 索引上的合并
* 有时 DataFrame 中的连接键位于其索引中，在这种情况下，可以传入 left_index=True 或 right_index=True 或两个都传，以说明索引应该被用作连接键。
* 层次化索引也是索引，需要以列表的形式指明用作合并键的多个列。
```py
In [173]: lefth
Out[173]: 
   data    key1  key2
0   0.0    Ohio  2000
1   1.0    Ohio  2001
2   2.0    Ohio  2002
3   3.0  Nevada  2001
4   4.0  Nevada  2002

In [174]: righth
Out[174]: 
             event1  event2
Nevada 2001       0       1
       2000       2       3
Ohio   2000       4       5
       2000       6       7
       2001       8       9
       2002      10      11

In [175]: pd.merge(lefth,righth,left_on=['key1','key2'],right_index=True)
Out[175]: 
   data    key1  key2  event1  event2
0   0.0    Ohio  2000       4       5
0   0.0    Ohio  2000       6       7
1   1.0    Ohio  2001       8       9
2   2.0    Ohio  2002      10      11
3   3.0  Nevada  2001       0       1
```
* 还可以左右都按照索引来，同时有一个方便的 join 方法。join 默认是 left，可以根据需要设置 how 为 inner，left，right，outer。
```py
In [176]: left2 = DataFrame([[1,2],[3,4],[5,6]],index=['a','b','c'],columns=['Ohio','Nevada'])

In [177]: left2
Out[177]: 
   Ohio  Nevada
a     1       2
b     3       4
c     5       6

In [178]: right2 = DataFrame([[7,8],[9,10],[11,12],[13,14]],index=['b','c','d','e'],columns=['Missouri','Albama'])

In [179]: right2
Out[179]: 
   Missouri  Albama
b         7       8
c         9      10
d        11      12
e        13      14

In [180]: pd.merge(left2,right2,left_index=True,right_index=True)
Out[180]: 
   Ohio  Nevada  Missouri  Albama
b     3       4         7       8
c     5       6         9      10

In [181]: pd.merge(left2,right2,left_index=True,right_index=True,how='outer')
Out[181]: 
   Ohio  Nevada  Missouri  Albama
a   1.0     2.0       NaN     NaN
b   3.0     4.0       7.0     8.0
c   5.0     6.0       9.0    10.0
d   NaN     NaN      11.0    12.0
e   NaN     NaN      13.0    14.0

In [182]: left2.join(right2,how='outer')
Out[182]: 
   Ohio  Nevada  Missouri  Albama
a   1.0     2.0       NaN     NaN
b   3.0     4.0       7.0     8.0
c   5.0     6.0       9.0    10.0
d   NaN     NaN      11.0    12.0
e   NaN     NaN      13.0    14.0

In [183]: left2.join(right2)
Out[183]: 
   Ohio  Nevada  Missouri  Albama
a     1       2       NaN     NaN
b     3       4       7.0     8.0
c     5       6       9.0    10.0
```
09. 轴向连接
* 另一种收据合并运算也被称作连接(concatenation)、绑定(binding)或堆叠(stacking)。NumPy 有一个用于合并原始 NumPy 数组的 concatenation 函数。
```py
In [186]: arr = np.arange(12).reshape((3,4))

In [187]: arr
Out[187]: 
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])

In [188]: np.concatenate([arr,arr],axis = 1)
Out[188]: 
array([[ 0,  1,  2,  3,  0,  1,  2,  3],
       [ 4,  5,  6,  7,  4,  5,  6,  7],
       [ 8,  9, 10, 11,  8,  9, 10, 11]])

In [189]: np.concatenate([arr,arr])
Out[189]: 
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11],
       [ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])
```

# [2017-10-11 利用 python 进行数据分析 数据规整化：清理、转换、合并、重塑]
01. pandas 对象的 轴标签连接。
* 没有重叠索引的 Series
```py
In [190]: s1 = Series([0,1],index=['a','b'])

In [191]: s2 = Series([2,3,4],index=['c','d','e'])

In [192]: s3 = Series([5,6],index=['f','g'])

In [193]: pd.concat([s1,s2,s3])
Out[193]: 
a    0
b    1
c    2
d    3
e    4
f    5
g    6
dtype: int64

# 默认情况下，是在 axis=0 上工作的，最终产生一个新的 Series。如果传入 axis=1，则结果就会变成一个 DataFrame。
In [194]: pd.concat([s1,s2,s3],axis = 1)
Out[194]: 
     0    1    2
a  0.0  NaN  NaN
b  1.0  NaN  NaN
c  NaN  2.0  NaN
d  NaN  3.0  NaN
e  NaN  4.0  NaN
f  NaN  NaN  5.0
g  NaN  NaN  6.0

# 传入 join=‘inner’ 即可得到他们的交集
In [200]: pd.concat([s1,s4],axis=1)
Out[200]: 
     0  1
a  0.0  0
b  1.0  5
f  NaN  5
g  NaN  6

In [201]: pd.concat([s1,s4],axis=1,join='inner')
Out[201]: 
   0  1
a  0  0
b  1  5

# 可以通过 join_axes 指定要在其他轴上使用的索引。
In [203]: pd.concat([s1,s4],axis=1,join_axes=[['a','c','b','e']])
Out[203]: 
     0    1
a  0.0  0.0
c  NaN  NaN
b  1.0  5.0
e  NaN  NaN

# 参与连接的 Series 在结果中区分不开，如果要在连接轴上创建一个层次化索引，使用 keys 参数可以达到这个目的。
In [207]: result = pd.concat([s1,s1,s3],keys=['one','two','three'])

In [208]: result
Out[208]: 
one    a    0
       b    1
two    a    0
       b    1
three  f    5
       g    6
dtype: int64

In [209]: result.unstack()
Out[209]: 
         a    b    f    g
one    0.0  1.0  NaN  NaN
two    0.0  1.0  NaN  NaN
three  NaN  NaN  5.0  6.0

# 如果沿着 axis=1 对 Series 进行合并，则 keys 就会成为 DataFrame 的列头
In [211]: pd.concat([s1,s2,s3],axis = 1,keys=['one','two','three'])
Out[211]: 
   one  two  three
a  0.0  NaN    NaN
b  1.0  NaN    NaN
c  NaN  2.0    NaN
d  NaN  3.0    NaN
e  NaN  4.0    NaN
f  NaN  NaN    5.0
g  NaN  NaN    6.0
```
02. DataFrame 的连接操作。
```py
# 示例
In [228]: df1
Out[228]: 
   one  two
a    0    1
b    2    3
c    4    5

In [229]: df2
Out[229]: 
   three  four
a      0     1
c      2     3

In [230]: pd.concat([df1,df2],axis=1,keys=['level1','level2'])
Out[230]: 
  level1     level2     
     one two  three four
a      0   1    0.0  1.0
b      2   3    NaN  NaN
c      4   5    2.0  3.0

# 如果传入一个字典，则字典的键会被当作 keys 选项的值。
In [231]: pd.concat({'level1':df1,'level2':df2},axis=1)
Out[231]: 
  level1     level2     
     one two  three four
a      0   1    0.0  1.0
b      2   3    NaN  NaN
c      4   5    2.0  3.0

# 此外有一个用于管理层次化索引的参数 names。
In [233]: pd.concat([df1,df2],axis=1,keys=['level1','level2'],names=['upper','lower'])
Out[233]: 
upper level1     level2     
lower    one two  three four
a          0   1    0.0  1.0
b          2   3    NaN  NaN
c          4   5    2.0  3.0

# 此外，还需要考虑的是跟当前分析工作无关的 DataFrame 行索引，即行索引是没有意义的。
```py
In [234]: df1 = DataFrame(np.random.randn(3,4),columns=['a','b','c','d'])

In [235]: df2 = DataFrame(np.random.randn(2,3),columns=['a','b','c'])

In [236]: df1
Out[236]: 
          a         b         c         d
0 -0.343936 -0.212204  0.004321 -0.233717
1 -0.423568  0.593723  0.323924  0.716182
2 -0.041621 -0.192263  0.257045  0.240745

In [237]: df2
Out[237]: 
          a         b         c
0  0.534535 -0.365767  0.727312
1  1.162773 -0.476623  0.334495

In [238]: pd.concat([df1,df2],ignore_index=True)
Out[238]: 
          a         b         c         d
0 -0.343936 -0.212204  0.004321 -0.233717
1 -0.423568  0.593723  0.323924  0.716182
2 -0.041621 -0.192263  0.257045  0.240745
3  0.534535 -0.365767  0.727312       NaN
4  1.162773 -0.476623  0.334495       NaN

# concat 函数的参数。
objs
axis
join
join_axes
keys
levels
names
verify_integrity
ignore_index
```
03. 合并重叠数据
* np.where 用于表达一种矢量化的 if-else。
* Series 有一个 conbine_first 方法，实现合并重复数据，并且会进行数据对齐，当有重复数据时，选择使用前边的数据。
```py
In [6]: a = Series([np.nan,2.5,np.nan,3.5,4.5,np.nan],index=['f','e','d','c','b','a'])

In [7]: b = Series(np.arange(len(a),dtype=np.float64),index=['f','e','d','c','b','a'])

In [13]: np.where(pd.isnull(a),b,a)
Out[13]: array([ 0. ,  2.5,  2. ,  3.5,  4.5,  nan])

 b[:-2].combine_first(a[2:])
Out[16]: 
a    NaN
b    4.5
c    3.0
d    2.0
e    1.0
f    0.0
dtype: float64
```
* 对于 DataFrame，conbine_first 可以看作用参数对象中的数据为调用者的缺失数据打补丁。
```py
In [21]: df1 = DataFrame({'a':[1.,np.nan,5.,np.nan],'b':[np.nan,2.,np.nan,6.],'c':range(2,18,4)})

In [22]: df1
Out[22]: 
     a    b   c
0  1.0  NaN   2
1  NaN  2.0   6
2  5.0  NaN  10
3  NaN  6.0  14

In [23]: df2 = DataFrame({'a':[5.,4.,np.nan,3.,7.],'b':[np.nan,3.,4.,6.,8.]})

In [24]: df2
Out[24]: 
     a    b
0  5.0  NaN
1  4.0  3.0
2  NaN  4.0
3  3.0  6.0
4  7.0  8.0

In [25]: df1.combine_first(df2)
Out[25]: 
     a    b     c
0  1.0  NaN   2.0
1  4.0  2.0   6.0
2  5.0  4.0  10.0
3  3.0  6.0  14.0
4  7.0  8.0   NaN
```
04. 重塑和轴向旋转
* 有许多用于重新排列表格型数据的基础运算，这些函数也称作重塑 reshape 或 轴向旋转 pivot
* 重塑层次化索引 stack 将数据的列旋转为行 unstack 将数据的行旋转为列。层次化索引的 Series 可以用 unstack 重新排列为一个 DataFrame
```py
In [56]: data
Out[56]: 
number    one  two  three
state                    
Ohio        0    1      2
Colorado    3    4      5

In [57]: result = data.stack()

In [58]: result
Out[58]: 
state     number
Ohio      one       0
          two       1
          three     2
Colorado  one       3
          two       4
          three     5
dtype: int64

In [59]: result.unstack()
Out[59]: 
number    one  two  three
state                    
Ohio        0    1      2
Colorado    3    4      5

# 默认情况下，unstack／stack 操作的是最内层，传入分层级别的编号或名称即可对其他级别进行 unstack 操作。
In [63]: result.unstack(0)
Out[63]: 
state   Ohio  Colorado
number                
one        0         3
two        1         4
three      2         5

In [65]: result.unstack('state')
Out[65]: 
state   Ohio  Colorado
number                
one        0         3
two        1         4
three      2         5

# 如果不是所有的级别值都能在各分组中找到的话，则 unstack 操作可能会引入缺失数据，stack 默认会滤除缺失数据，因此该运算时可逆的。
# 在对 DataFrame 进行 unstack 操作时，作为旋转轴的级别将会成为结果中的最低级别。
In [76]: df = DataFrame({'left':result,'right':result+5},columns=pd.Index(['left','right'],name='side'))

In [77]: df
Out[77]: 
side             left  right
state    number             
Ohio     one        0      5
         two        1      6
         three      2      7
Colorado one        3      8
         two        4      9
         three      5     10

In [78]: df.unstack('state')
Out[78]: 
side   left          right         
state  Ohio Colorado  Ohio Colorado
number                             
one       0        3     5        8
two       1        4     6        9
three     2        5     7       10

In [79]: df.unstack('state').stack('side')
Out[79]: 
state         Colorado  Ohio
number side                 
one    left          3     0
       right         8     5
two    left          4     1
       right         9     6
three  left          5     2
       right        10     7

```








